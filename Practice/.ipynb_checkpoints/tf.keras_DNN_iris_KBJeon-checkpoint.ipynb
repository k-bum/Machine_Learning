{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "     ---------------------------------------- 455.9/455.9 MB 241.7 kB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 462.4 kB/s eta 0:00:00\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "     ---------------------------------------- 5.9/5.9 MB 701.4 kB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "     ---------------------------------------- 123.4/123.4 kB 516.5 kB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "     ---------------------------------------- 438.7/438.7 kB 638.5 kB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     ---------------------------------------- 895.9/895.9 kB 623.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (1.22.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 628.9 kB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "     ---------------------------------------- 14.2/14.2 MB 196.6 kB/s eta 0:00:00\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 161.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 587.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 302.8 kB/s eta 0:00:00\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.6/42.6 kB 159.3 kB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.49.1-cp39-cp39-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 297.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ---------------------------------------- 781.3/781.3 kB 146.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.25.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n",
      "     ---------------------------------------- 169.8/169.8 kB 83.6 kB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.3/93.3 kB 161.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     ---------------------------------------- 155.3/155.3 kB 309.2 kB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB 608.2 kB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 151.7/151.7 kB 312.2 kB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, keras-preprocessing, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.9.24 gast-0.4.0 google-auth-2.12.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.49.1 h5py-3.7.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.1 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 wrapt-1.14.1\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "     ---------------------------------------- 455.9/455.9 MB 605.3 kB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (1.22.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.49.1-cp39-cp39-win_amd64.whl (3.6 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.25.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, keras-preprocessing, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.9.24 gast-0.4.0 google-auth-2.12.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.49.1 h5py-3.7.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.1 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "22UZuhWkLtVt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers  # 모듈(변수나 함수를 포함)만 불러오기\n",
    "\n",
    "# BMI 데이터를 읽어 들이고 정규화하기\n",
    "df = pd.read_csv(\"iris.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "3GAFF1QOk58E",
    "outputId": "333e58a1-4a26-4f5e-b366-a5efc04501b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>iris_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width        iris_type\n",
       "0             6.4          3.1           5.5          1.8   Iris-virginica\n",
       "1             6.5          3.0           5.8          2.2   Iris-virginica\n",
       "2             4.6          3.1           1.5          0.2      Iris-setosa\n",
       "3             6.4          2.8           5.6          2.1   Iris-virginica\n",
       "4             5.0          3.3           1.4          0.2      Iris-setosa\n",
       "..            ...          ...           ...          ...              ...\n",
       "145           5.1          3.8           1.9          0.4      Iris-setosa\n",
       "146           5.7          2.8           4.5          1.3  Iris-versicolor\n",
       "147           6.9          3.1           5.4          2.1   Iris-virginica\n",
       "148           7.2          3.0           5.8          1.6   Iris-virginica\n",
       "149           4.9          3.0           1.4          0.2      Iris-setosa\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sepal_length  sepal_width  petal_length  petal_width\n",
      "iris_type                                                            \n",
      "Iris-setosa                50           50            50           50\n",
      "Iris-versicolor            50           50            50           50\n",
      "Iris-virginica             50           50            50           50\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('iris_type').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WaC6EJH_kwwz"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:4]\n",
    "\n",
    "# 레이블링, 라벨링 (labelling) => one-hot encoding\n",
    "bclass = {\"Iris-setosa\":[1,0,0], \"Iris-versicolor\":[0,1,0], \"Iris-virginica\":[0,0,1]}\n",
    "y = np.empty((150,3))     # 150x3 크기의 다차원 벡터 생성\n",
    "for i, v in enumerate(df[\"iris_type\"]):\n",
    "    y[i] = bclass[v]        # \"Iris-setosa\"이면, y[i]=[1,0,0] 와 같이 할당\n",
    "    \n",
    "# 훈련 전용 데이터와 테스트 전용 데이터로 나누기\n",
    "X_train, y_train = X[0:100], y[0:100]\n",
    "X_test,  y_test  = X[100:150], y[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "G2UgYhccLtVu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 구조 정의하기\n",
    "model = tf.keras.Sequential()         # 순차적 계층화 준비\n",
    "model.add(layers.Dense(10, input_shape=(4,)))  # 입력 4개로부터 전달받는 10개 노드의 layer 생성\n",
    "model.add(layers.Activation('softplus'))  # 활성화함수 채택(hidden layer)\n",
    "model.add(layers.Dropout(0.1))        # dropout ratio=10% (배치 훈련시 10% arc 무시)\n",
    "\n",
    "model.add(layers.Dense(8))            # 8개 노드의 layer 생성\n",
    "model.add(layers.Activation('softplus'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Dense(3))\n",
    "model.add(layers.Activation('softmax'))# 분류(classification)을 위해 softmax 함수 사용\n",
    "\n",
    "# 모델 구축하기\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # 다중 교차엔트로피\n",
    "    optimizer=\"rmsprop\",   # 최적화 기법 중 하나\n",
    "    metrics=['accuracy'])  # 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IhHchdXLtVv",
    "outputId": "bc0045b9-353e-4f65-ec94-d7b114c8f41e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 150ms/step - loss: 1.5784 - accuracy: 0.1222 - val_loss: 1.2175 - val_accuracy: 0.2000\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5108 - accuracy: 0.0889 - val_loss: 1.2044 - val_accuracy: 0.2000\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3150 - accuracy: 0.2222 - val_loss: 1.2010 - val_accuracy: 0.1000\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3154 - accuracy: 0.1556 - val_loss: 1.2065 - val_accuracy: 0.2000\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2917 - accuracy: 0.1222 - val_loss: 1.2013 - val_accuracy: 0.3000\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2121 - accuracy: 0.3111 - val_loss: 1.1964 - val_accuracy: 0.1000\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2370 - accuracy: 0.2667 - val_loss: 1.1968 - val_accuracy: 0.2000\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2045 - accuracy: 0.2778 - val_loss: 1.1990 - val_accuracy: 0.2000\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1942 - accuracy: 0.3667 - val_loss: 1.1936 - val_accuracy: 0.3000\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2265 - accuracy: 0.3556 - val_loss: 1.1706 - val_accuracy: 0.4000\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.1903 - accuracy: 0.3667 - val_loss: 1.1552 - val_accuracy: 0.5000\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2165 - accuracy: 0.4000 - val_loss: 1.1477 - val_accuracy: 0.4000\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.1489 - accuracy: 0.4000 - val_loss: 1.1144 - val_accuracy: 0.7000\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0913 - accuracy: 0.4556 - val_loss: 1.0981 - val_accuracy: 0.7000\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1207 - accuracy: 0.4556 - val_loss: 1.0821 - val_accuracy: 0.7000\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1447 - accuracy: 0.4333 - val_loss: 1.0509 - val_accuracy: 0.7000\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1279 - accuracy: 0.4444 - val_loss: 1.0313 - val_accuracy: 0.7000\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0327 - accuracy: 0.5333 - val_loss: 1.0113 - val_accuracy: 0.7000\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0696 - accuracy: 0.4556 - val_loss: 0.9871 - val_accuracy: 0.7000\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0825 - accuracy: 0.4444 - val_loss: 0.9740 - val_accuracy: 0.7000\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0125 - accuracy: 0.5222 - val_loss: 0.9448 - val_accuracy: 0.7000\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.9964 - accuracy: 0.5667 - val_loss: 0.9196 - val_accuracy: 0.7000\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.9934 - accuracy: 0.5667 - val_loss: 0.9089 - val_accuracy: 0.7000\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.9834 - accuracy: 0.5778 - val_loss: 0.8957 - val_accuracy: 0.7000\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0423 - accuracy: 0.5222 - val_loss: 0.8687 - val_accuracy: 0.7000\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.9377 - accuracy: 0.5889 - val_loss: 0.8523 - val_accuracy: 0.7000\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.8684 - accuracy: 0.5889 - val_loss: 0.8260 - val_accuracy: 0.7000\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.9419 - accuracy: 0.5111 - val_loss: 0.8063 - val_accuracy: 0.7000\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.8551 - accuracy: 0.5889 - val_loss: 0.7934 - val_accuracy: 0.7000\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.8728 - accuracy: 0.6000 - val_loss: 0.7763 - val_accuracy: 0.7000\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.9297 - accuracy: 0.5889 - val_loss: 0.7506 - val_accuracy: 0.7000\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.8821 - accuracy: 0.6111 - val_loss: 0.7335 - val_accuracy: 0.7000\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.8489 - accuracy: 0.6444 - val_loss: 0.7082 - val_accuracy: 0.7000\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.8300 - accuracy: 0.5778 - val_loss: 0.6977 - val_accuracy: 0.7000\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.7961 - accuracy: 0.5667 - val_loss: 0.6763 - val_accuracy: 0.7000\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7941 - accuracy: 0.6000 - val_loss: 0.6622 - val_accuracy: 0.7000\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.8281 - accuracy: 0.5889 - val_loss: 0.6496 - val_accuracy: 0.7000\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.7836 - accuracy: 0.6778 - val_loss: 0.6371 - val_accuracy: 0.7000\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.7684 - accuracy: 0.6222 - val_loss: 0.6204 - val_accuracy: 0.7000\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7473 - accuracy: 0.7111 - val_loss: 0.6007 - val_accuracy: 0.7000\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.7377 - accuracy: 0.6444 - val_loss: 0.5746 - val_accuracy: 0.7000\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7259 - accuracy: 0.6556 - val_loss: 0.5665 - val_accuracy: 0.7000\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.8432 - accuracy: 0.5111 - val_loss: 0.5532 - val_accuracy: 0.7000\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.7845 - accuracy: 0.5778 - val_loss: 0.5371 - val_accuracy: 0.7000\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.7559 - accuracy: 0.5889 - val_loss: 0.5149 - val_accuracy: 0.7000\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7394 - accuracy: 0.6000 - val_loss: 0.5041 - val_accuracy: 0.7000\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7349 - accuracy: 0.6778 - val_loss: 0.5062 - val_accuracy: 0.7000\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6752 - accuracy: 0.6667 - val_loss: 0.5025 - val_accuracy: 0.7000\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6876 - accuracy: 0.6667 - val_loss: 0.4839 - val_accuracy: 0.7000\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7511 - accuracy: 0.6111 - val_loss: 0.4745 - val_accuracy: 0.7000\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6470 - accuracy: 0.7000 - val_loss: 0.4549 - val_accuracy: 0.8000\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6683 - accuracy: 0.7333 - val_loss: 0.4331 - val_accuracy: 0.9000\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6494 - accuracy: 0.6667 - val_loss: 0.4259 - val_accuracy: 0.9000\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6746 - accuracy: 0.7222 - val_loss: 0.4099 - val_accuracy: 0.9000\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6228 - accuracy: 0.7333 - val_loss: 0.4152 - val_accuracy: 0.8000\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6346 - accuracy: 0.7444 - val_loss: 0.4055 - val_accuracy: 0.9000\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6711 - accuracy: 0.7222 - val_loss: 0.4052 - val_accuracy: 0.8000\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6088 - accuracy: 0.7889 - val_loss: 0.3893 - val_accuracy: 0.9000\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6455 - accuracy: 0.7444 - val_loss: 0.3799 - val_accuracy: 0.9000\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6286 - accuracy: 0.7222 - val_loss: 0.3772 - val_accuracy: 0.9000\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6352 - accuracy: 0.7333 - val_loss: 0.3673 - val_accuracy: 0.9000\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6667 - accuracy: 0.6889 - val_loss: 0.3634 - val_accuracy: 0.9000\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6355 - accuracy: 0.6778 - val_loss: 0.3652 - val_accuracy: 0.8000\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6301 - accuracy: 0.6556 - val_loss: 0.3591 - val_accuracy: 0.9000\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5982 - accuracy: 0.7333 - val_loss: 0.3581 - val_accuracy: 0.8000\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6210 - accuracy: 0.7000 - val_loss: 0.3578 - val_accuracy: 0.8000\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5878 - accuracy: 0.7444 - val_loss: 0.3487 - val_accuracy: 0.9000\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5742 - accuracy: 0.7889 - val_loss: 0.3373 - val_accuracy: 0.9000\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5780 - accuracy: 0.7778 - val_loss: 0.3276 - val_accuracy: 0.9000\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6279 - accuracy: 0.7222 - val_loss: 0.3237 - val_accuracy: 0.9000\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5992 - accuracy: 0.7889 - val_loss: 0.3121 - val_accuracy: 0.9000\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5561 - accuracy: 0.7667 - val_loss: 0.3068 - val_accuracy: 0.9000\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5739 - accuracy: 0.7444 - val_loss: 0.3091 - val_accuracy: 0.9000\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6347 - accuracy: 0.7222 - val_loss: 0.3047 - val_accuracy: 0.9000\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5855 - accuracy: 0.7111 - val_loss: 0.3038 - val_accuracy: 0.9000\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5715 - accuracy: 0.7667 - val_loss: 0.3072 - val_accuracy: 0.9000\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5178 - accuracy: 0.8000 - val_loss: 0.3097 - val_accuracy: 0.9000\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5030 - accuracy: 0.8556 - val_loss: 0.2979 - val_accuracy: 0.9000\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.5612 - accuracy: 0.7667 - val_loss: 0.2919 - val_accuracy: 0.9000\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5598 - accuracy: 0.7333 - val_loss: 0.2950 - val_accuracy: 0.9000\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5520 - accuracy: 0.7778 - val_loss: 0.2852 - val_accuracy: 0.9000\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5106 - accuracy: 0.7556 - val_loss: 0.2861 - val_accuracy: 0.9000\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.5369 - accuracy: 0.7556 - val_loss: 0.2822 - val_accuracy: 0.9000\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4351 - accuracy: 0.8778 - val_loss: 0.2820 - val_accuracy: 0.9000\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5086 - accuracy: 0.8111 - val_loss: 0.2812 - val_accuracy: 0.9000\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.5334 - accuracy: 0.7889 - val_loss: 0.2757 - val_accuracy: 0.9000\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5178 - accuracy: 0.7889 - val_loss: 0.2723 - val_accuracy: 0.9000\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5003 - accuracy: 0.8000 - val_loss: 0.2662 - val_accuracy: 0.9000\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5967 - accuracy: 0.7111 - val_loss: 0.2638 - val_accuracy: 0.9000\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5153 - accuracy: 0.7889 - val_loss: 0.2564 - val_accuracy: 0.9000\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5344 - accuracy: 0.7333 - val_loss: 0.2608 - val_accuracy: 0.9000\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4559 - accuracy: 0.8444 - val_loss: 0.2589 - val_accuracy: 0.9000\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4898 - accuracy: 0.8111 - val_loss: 0.2481 - val_accuracy: 0.9000\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4771 - accuracy: 0.8222 - val_loss: 0.2513 - val_accuracy: 0.9000\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5198 - accuracy: 0.7889 - val_loss: 0.2426 - val_accuracy: 0.9000\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4807 - accuracy: 0.8222 - val_loss: 0.2405 - val_accuracy: 0.9000\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4635 - accuracy: 0.8556 - val_loss: 0.2379 - val_accuracy: 0.9000\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5653 - accuracy: 0.7556 - val_loss: 0.2428 - val_accuracy: 0.9000\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4318 - accuracy: 0.8444 - val_loss: 0.2342 - val_accuracy: 0.9000\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3573 - accuracy: 0.8889 - val_loss: 0.2401 - val_accuracy: 0.9000\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4025 - accuracy: 0.8333 - val_loss: 0.2383 - val_accuracy: 0.9000\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4915 - accuracy: 0.7778 - val_loss: 0.2307 - val_accuracy: 0.9000\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4847 - accuracy: 0.8000 - val_loss: 0.2262 - val_accuracy: 0.9000\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4927 - accuracy: 0.8000 - val_loss: 0.2249 - val_accuracy: 0.9000\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4200 - accuracy: 0.8556 - val_loss: 0.2253 - val_accuracy: 0.9000\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4490 - accuracy: 0.8333 - val_loss: 0.2159 - val_accuracy: 0.9000\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3998 - accuracy: 0.8333 - val_loss: 0.2278 - val_accuracy: 0.9000\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4703 - accuracy: 0.7667 - val_loss: 0.2250 - val_accuracy: 0.9000\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4647 - accuracy: 0.8222 - val_loss: 0.2281 - val_accuracy: 0.9000\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4641 - accuracy: 0.8556 - val_loss: 0.2285 - val_accuracy: 0.9000\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4200 - accuracy: 0.8889 - val_loss: 0.2140 - val_accuracy: 0.9000\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.2205 - val_accuracy: 0.9000\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4384 - accuracy: 0.8333 - val_loss: 0.2199 - val_accuracy: 0.9000\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4372 - accuracy: 0.8333 - val_loss: 0.2186 - val_accuracy: 0.9000\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4210 - accuracy: 0.8667 - val_loss: 0.2191 - val_accuracy: 0.9000\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4450 - accuracy: 0.8111 - val_loss: 0.2125 - val_accuracy: 0.9000\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3648 - accuracy: 0.8778 - val_loss: 0.2109 - val_accuracy: 0.9000\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4442 - accuracy: 0.8333 - val_loss: 0.2011 - val_accuracy: 0.9000\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4358 - accuracy: 0.8000 - val_loss: 0.1982 - val_accuracy: 0.9000\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4246 - accuracy: 0.8333 - val_loss: 0.2023 - val_accuracy: 0.9000\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4185 - accuracy: 0.8556 - val_loss: 0.2002 - val_accuracy: 0.9000\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4228 - accuracy: 0.7889 - val_loss: 0.1967 - val_accuracy: 0.9000\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3839 - accuracy: 0.8556 - val_loss: 0.2015 - val_accuracy: 0.9000\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4075 - accuracy: 0.8444 - val_loss: 0.1965 - val_accuracy: 0.9000\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3807 - accuracy: 0.8333 - val_loss: 0.1972 - val_accuracy: 0.9000\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4353 - accuracy: 0.8111 - val_loss: 0.1902 - val_accuracy: 0.9000\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3580 - accuracy: 0.8333 - val_loss: 0.1858 - val_accuracy: 0.9000\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3881 - accuracy: 0.8444 - val_loss: 0.1825 - val_accuracy: 0.9000\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3409 - accuracy: 0.8889 - val_loss: 0.1913 - val_accuracy: 0.9000\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3910 - accuracy: 0.8444 - val_loss: 0.1880 - val_accuracy: 0.9000\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3845 - accuracy: 0.8444 - val_loss: 0.1953 - val_accuracy: 0.9000\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4301 - accuracy: 0.8333 - val_loss: 0.1948 - val_accuracy: 0.9000\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4613 - accuracy: 0.7333 - val_loss: 0.1832 - val_accuracy: 0.9000\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3922 - accuracy: 0.8556 - val_loss: 0.1829 - val_accuracy: 0.9000\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4073 - accuracy: 0.8000 - val_loss: 0.1817 - val_accuracy: 0.9000\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3567 - accuracy: 0.8667 - val_loss: 0.1783 - val_accuracy: 0.9000\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4266 - accuracy: 0.8444 - val_loss: 0.1724 - val_accuracy: 0.9000\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3152 - accuracy: 0.8889 - val_loss: 0.1685 - val_accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3790 - accuracy: 0.8222 - val_loss: 0.1682 - val_accuracy: 0.9000\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3945 - accuracy: 0.8333 - val_loss: 0.1655 - val_accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3412 - accuracy: 0.8556 - val_loss: 0.1628 - val_accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3878 - accuracy: 0.8444 - val_loss: 0.1568 - val_accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3551 - accuracy: 0.8889 - val_loss: 0.1563 - val_accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3449 - accuracy: 0.8778 - val_loss: 0.1509 - val_accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3238 - accuracy: 0.8778 - val_loss: 0.1501 - val_accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3848 - accuracy: 0.8000 - val_loss: 0.1597 - val_accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3495 - accuracy: 0.8333 - val_loss: 0.1634 - val_accuracy: 0.9000\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4231 - accuracy: 0.8444 - val_loss: 0.1496 - val_accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4225 - accuracy: 0.7889 - val_loss: 0.1424 - val_accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3430 - accuracy: 0.8333 - val_loss: 0.1475 - val_accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3767 - accuracy: 0.8111 - val_loss: 0.1484 - val_accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3512 - accuracy: 0.8444 - val_loss: 0.1476 - val_accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3844 - accuracy: 0.8444 - val_loss: 0.1465 - val_accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3792 - accuracy: 0.8333 - val_loss: 0.1533 - val_accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2490 - accuracy: 0.9222 - val_loss: 0.1523 - val_accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3570 - accuracy: 0.8333 - val_loss: 0.1552 - val_accuracy: 0.9000\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3342 - accuracy: 0.8667 - val_loss: 0.1428 - val_accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2890 - accuracy: 0.8667 - val_loss: 0.1453 - val_accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3604 - accuracy: 0.8444 - val_loss: 0.1489 - val_accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3596 - accuracy: 0.8444 - val_loss: 0.1381 - val_accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4126 - accuracy: 0.8444 - val_loss: 0.1376 - val_accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3943 - accuracy: 0.8222 - val_loss: 0.1366 - val_accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3482 - accuracy: 0.8333 - val_loss: 0.1409 - val_accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3282 - accuracy: 0.8444 - val_loss: 0.1297 - val_accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2751 - accuracy: 0.8889 - val_loss: 0.1336 - val_accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3771 - accuracy: 0.8444 - val_loss: 0.1363 - val_accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2905 - accuracy: 0.8778 - val_loss: 0.1332 - val_accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3383 - accuracy: 0.8333 - val_loss: 0.1308 - val_accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2935 - accuracy: 0.8889 - val_loss: 0.1312 - val_accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3175 - accuracy: 0.8333 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3536 - accuracy: 0.8556 - val_loss: 0.1238 - val_accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3765 - accuracy: 0.8667 - val_loss: 0.1203 - val_accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2868 - accuracy: 0.8778 - val_loss: 0.1180 - val_accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3817 - accuracy: 0.8333 - val_loss: 0.1208 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3299 - accuracy: 0.8667 - val_loss: 0.1268 - val_accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2803 - accuracy: 0.8556 - val_loss: 0.1266 - val_accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3328 - accuracy: 0.8778 - val_loss: 0.1287 - val_accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3281 - accuracy: 0.8556 - val_loss: 0.1279 - val_accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3954 - accuracy: 0.8333 - val_loss: 0.1259 - val_accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4109 - accuracy: 0.8222 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2807 - accuracy: 0.8556 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3413 - accuracy: 0.8556 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3153 - accuracy: 0.8556 - val_loss: 0.1129 - val_accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3169 - accuracy: 0.8556 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3627 - accuracy: 0.8222 - val_loss: 0.1188 - val_accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3304 - accuracy: 0.8222 - val_loss: 0.1175 - val_accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3159 - accuracy: 0.8667 - val_loss: 0.1255 - val_accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3444 - accuracy: 0.8778 - val_loss: 0.1262 - val_accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3230 - accuracy: 0.8556 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3139 - accuracy: 0.8667 - val_loss: 0.1168 - val_accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3054 - accuracy: 0.8778 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3131 - accuracy: 0.8444 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3299 - accuracy: 0.8111 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2511 - accuracy: 0.8778 - val_loss: 0.1169 - val_accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3034 - accuracy: 0.8889 - val_loss: 0.1060 - val_accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2875 - accuracy: 0.8667 - val_loss: 0.1065 - val_accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3051 - accuracy: 0.8778 - val_loss: 0.1031 - val_accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3721 - accuracy: 0.8333 - val_loss: 0.1115 - val_accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2452 - accuracy: 0.9222 - val_loss: 0.1100 - val_accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2771 - accuracy: 0.9000 - val_loss: 0.1050 - val_accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3594 - accuracy: 0.8222 - val_loss: 0.1066 - val_accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2986 - accuracy: 0.9000 - val_loss: 0.0989 - val_accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3013 - accuracy: 0.8778 - val_loss: 0.0987 - val_accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2773 - accuracy: 0.8667 - val_loss: 0.1029 - val_accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2769 - accuracy: 0.8667 - val_loss: 0.1037 - val_accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2368 - accuracy: 0.9222 - val_loss: 0.1043 - val_accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3226 - accuracy: 0.8333 - val_loss: 0.0968 - val_accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2887 - accuracy: 0.9333 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2731 - accuracy: 0.8556 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2540 - accuracy: 0.8889 - val_loss: 0.0990 - val_accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.2927 - accuracy: 0.8667 - val_loss: 0.0995 - val_accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2557 - accuracy: 0.9111 - val_loss: 0.0901 - val_accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2623 - accuracy: 0.8778 - val_loss: 0.0887 - val_accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2539 - accuracy: 0.8889 - val_loss: 0.0893 - val_accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3172 - accuracy: 0.8444 - val_loss: 0.0918 - val_accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2670 - accuracy: 0.9000 - val_loss: 0.0910 - val_accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2990 - accuracy: 0.8333 - val_loss: 0.0918 - val_accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2868 - accuracy: 0.8667 - val_loss: 0.0951 - val_accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2582 - accuracy: 0.9000 - val_loss: 0.0878 - val_accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3058 - accuracy: 0.8778 - val_loss: 0.0903 - val_accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3058 - accuracy: 0.8778 - val_loss: 0.0808 - val_accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2284 - accuracy: 0.8778 - val_loss: 0.0813 - val_accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2563 - accuracy: 0.9222 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2636 - accuracy: 0.9000 - val_loss: 0.0908 - val_accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2732 - accuracy: 0.8778 - val_loss: 0.0848 - val_accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3687 - accuracy: 0.8000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3090 - accuracy: 0.8778 - val_loss: 0.0805 - val_accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2900 - accuracy: 0.9111 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2453 - accuracy: 0.9000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2879 - accuracy: 0.8444 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2262 - accuracy: 0.9111 - val_loss: 0.0870 - val_accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2308 - accuracy: 0.8889 - val_loss: 0.0767 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2618 - accuracy: 0.9111 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2151 - accuracy: 0.9222 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2306 - accuracy: 0.9000 - val_loss: 0.0792 - val_accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2895 - accuracy: 0.8778 - val_loss: 0.0731 - val_accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3045 - accuracy: 0.8333 - val_loss: 0.0691 - val_accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2243 - accuracy: 0.8889 - val_loss: 0.0716 - val_accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2701 - accuracy: 0.8889 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2287 - accuracy: 0.9000 - val_loss: 0.0846 - val_accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1958 - accuracy: 0.9111 - val_loss: 0.0847 - val_accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1993 - accuracy: 0.9444 - val_loss: 0.0855 - val_accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2479 - accuracy: 0.8667 - val_loss: 0.0894 - val_accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.0734 - val_accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2327 - accuracy: 0.8778 - val_loss: 0.0683 - val_accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2547 - accuracy: 0.9111 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2584 - accuracy: 0.9111 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2761 - accuracy: 0.8889 - val_loss: 0.0706 - val_accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.2689 - accuracy: 0.8778 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2323 - accuracy: 0.9000 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2733 - accuracy: 0.8667 - val_loss: 0.0734 - val_accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2302 - accuracy: 0.9333 - val_loss: 0.0706 - val_accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2996 - accuracy: 0.8778 - val_loss: 0.0707 - val_accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2595 - accuracy: 0.9111 - val_loss: 0.0731 - val_accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2898 - accuracy: 0.8667 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2587 - accuracy: 0.9000 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2315 - accuracy: 0.8778 - val_loss: 0.0799 - val_accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.2487 - accuracy: 0.8889 - val_loss: 0.0691 - val_accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2625 - accuracy: 0.9111 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2712 - accuracy: 0.9000 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3486 - accuracy: 0.8556 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2284 - accuracy: 0.9111 - val_loss: 0.0736 - val_accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2249 - accuracy: 0.9111 - val_loss: 0.0656 - val_accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2348 - accuracy: 0.8889 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2144 - accuracy: 0.9333 - val_loss: 0.0713 - val_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2342 - accuracy: 0.9222 - val_loss: 0.0689 - val_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2757 - accuracy: 0.8889 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2299 - accuracy: 0.9111 - val_loss: 0.0713 - val_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.2993 - accuracy: 0.8667 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2702 - accuracy: 0.9111 - val_loss: 0.0687 - val_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2881 - accuracy: 0.9111 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1932 - accuracy: 0.9556 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1908 - accuracy: 0.9222 - val_loss: 0.0724 - val_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2078 - accuracy: 0.9111 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2884 - accuracy: 0.8889 - val_loss: 0.0677 - val_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2720 - accuracy: 0.8778 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1271 - accuracy: 1.0000\n",
      "test_loss:  0.127136692404747\n",
      "test_acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 훈련하기\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=20,     # 20개에 한 번씩 업데이터 실행\n",
    "    epochs=300,          # 전체 훈련 데이터셋을 총 200회 반복 실험. 단, 조기중지될 수 있음\n",
    "    validation_split=0.1,  \n",
    "        #validation data 분할 비율. 즉, 150개 중에서 20%인 30개를 validation용으로 분할\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)],  \n",
    "        #'val_loss'를 monitor하여 감소하면 10번 더 참고 조기중지(early stopping)\n",
    "    verbose=1)   # 전 과정을 화면에 출력(1) 또는 미출력(0) 모드\n",
    "\n",
    "# 테스트 데이터로 평가하기\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('test_loss: ', score[0])\n",
    "print('test_acc: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVZ2sf6Gb5Y-",
    "outputId": "e18e011e-5e3c-4b6d-9556-34d0db422f9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "Hh1NwcAwLtVw",
    "outputId": "828e6f60-2f2e-4576-dc99-53eddbc4066d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0LNN770LtVw",
    "outputId": "1d0a5184-5bb0-47e9-e5d4-5ac09faef69c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                50        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 10)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165\n",
      "Trainable params: 165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ap06VxZI5Aog",
    "outputId": "be69fe44-d828-4e2b-8e2e-8fabb0ee181a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.2982965 , -0.01925083,  0.49449033,  0.23408562,  0.60687566,\n",
       "          0.3054502 ,  0.0666948 ,  0.23107128,  0.487092  , -0.1381525 ],\n",
       "        [ 0.00807161, -0.41206166, -0.42060462, -0.48316413,  0.27054328,\n",
       "          0.10901709,  0.7176184 ,  0.6266612 ,  0.62381893, -0.4877577 ],\n",
       "        [ 0.4223887 ,  0.42097193, -0.3146859 ,  0.63142776, -0.7178385 ,\n",
       "         -0.4437856 , -0.66866326, -0.5864377 , -0.71265095,  0.07702328],\n",
       "        [-0.2813243 ,  0.85155606, -0.3472216 ,  1.0496556 , -1.1084883 ,\n",
       "         -0.6457863 , -0.13036287, -0.46780327, -1.0535349 , -0.2220824 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.11301416,  0.02483081,  0.09926341, -0.14015773,  0.45606935,\n",
       "         0.24378435,  0.30625507,  0.01959829,  0.22193171,  0.2120644 ],\n",
       "       dtype=float32),\n",
       " array([[-0.40011215, -0.17935607,  0.43378145,  0.09242722,  0.26542673,\n",
       "         -0.12803064, -0.09775384,  0.689008  ],\n",
       "        [-0.84230024,  0.31859928,  0.01988879, -0.16371031, -0.08438499,\n",
       "         -0.5915286 ,  0.18785264,  0.5613377 ],\n",
       "        [-0.2076024 , -0.2944235 , -0.22960803,  0.46926028,  0.5129562 ,\n",
       "          0.35070884,  0.03637601,  0.2121135 ],\n",
       "        [-0.50749004,  0.31706542, -0.22597283, -0.21225534,  0.27729   ,\n",
       "         -0.09227852, -1.0199045 ,  0.4869294 ],\n",
       "        [ 0.6690312 , -0.13525304,  0.35001564,  0.8329602 , -0.09455963,\n",
       "          1.099835  ,  0.02521803, -0.926526  ],\n",
       "        [ 0.55373305, -0.2672423 ,  0.5507027 ,  0.23253997, -0.27370477,\n",
       "          1.0801162 ,  0.2746509 , -0.86937946],\n",
       "        [ 0.46003833, -0.2860535 , -0.3175997 ,  0.71455854, -0.16476725,\n",
       "          0.6818272 ,  0.36322376, -0.29278505],\n",
       "        [-0.03915316, -0.8392482 ,  0.39300215,  0.32849595, -0.21197464,\n",
       "          0.81406516,  0.32840005, -0.5158147 ],\n",
       "        [ 0.5390759 , -0.30794677, -0.10944255,  0.904257  , -0.13164337,\n",
       "          0.6747226 , -0.30368167, -0.12005109],\n",
       "        [-0.09474533,  0.16035937,  0.20130847,  0.35036978,  0.85320646,\n",
       "         -0.13162212, -0.17252223, -0.46693814]], dtype=float32),\n",
       " array([-0.02811833, -0.08709749,  0.00885402, -0.05940159,  0.31600484,\n",
       "        -0.10763545,  0.05226743,  0.28240743], dtype=float32),\n",
       " array([[ 0.40103692, -0.7858432 , -0.3571272 ],\n",
       "        [-0.23000848, -0.14269824,  0.6465687 ],\n",
       "        [-0.05020044,  0.5481301 , -0.35079414],\n",
       "        [ 0.3622587 ,  0.32719958, -0.8480823 ],\n",
       "        [-1.3973745 ,  0.31385309,  0.22020835],\n",
       "        [ 0.1903723 , -0.18706118, -0.9871809 ],\n",
       "        [-0.45250967, -0.6832349 ,  0.74068856],\n",
       "        [-1.5179951 , -0.04342746,  0.37321892]], dtype=float32),\n",
       " array([-0.4281529 ,  0.10206256,  0.11259404], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhPK4V6nLtVx",
    "outputId": "c191a145-aeb2-43de-dcab-c9a5229e7888",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                50        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 10)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165\n",
      "Trainable params: 165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1271 - accuracy: 1.0000\n",
      "test_loss:  0.127136692404747\n",
      "test_acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "model.save(\"dnn_iris.h5\")\n",
    "print(\"Saved model to disk.\")\n",
    "\n",
    "from numpy import loadtxt\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "# 저장된 모델 읽어오기\n",
    "loaded_model = load_model(\"dnn_iris.h5\")\n",
    "model.summary()\n",
    "\n",
    "# 모델을 평가하기\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('test_loss: ', score[0])\n",
    "print('test_acc: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8sQr21XLtVy",
    "outputId": "d5a57154-8a71-4852-dfa8-2d744b50db50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "[[9.99819219e-01 1.80852134e-04 9.21700108e-13]\n",
      " [5.59302748e-07 6.44870102e-02 9.35512424e-01]\n",
      " [5.63654066e-06 1.67105332e-01 8.32888961e-01]\n",
      " [2.66619138e-02 9.65028286e-01 8.30986537e-03]\n",
      " [3.82809930e-07 6.32926375e-02 9.36706960e-01]\n",
      " [9.99677181e-01 3.22885026e-04 5.11318115e-12]\n",
      " [9.99896526e-01 1.03426086e-04 7.10206037e-13]\n",
      " [9.99985456e-01 1.44892801e-05 3.60498916e-15]\n",
      " [2.31199047e-05 3.04325670e-01 6.95651174e-01]\n",
      " [4.33055266e-06 1.43345863e-01 8.56649816e-01]\n",
      " [7.50647625e-04 8.00279737e-01 1.98969662e-01]\n",
      " [9.99853849e-01 1.46152306e-04 7.98031996e-13]\n",
      " [4.16911254e-03 9.43942785e-01 5.18880971e-02]\n",
      " [9.99965072e-01 3.49274633e-05 3.51884490e-14]\n",
      " [8.85912217e-04 8.66898894e-01 1.32215112e-01]\n",
      " [6.41794850e-06 1.92506939e-01 8.07486653e-01]\n",
      " [4.43005047e-06 1.40875608e-01 8.59119952e-01]\n",
      " [8.69253185e-03 9.72526371e-01 1.87811460e-02]\n",
      " [5.81532111e-03 9.62628305e-01 3.15564275e-02]\n",
      " [9.99776065e-01 2.23998679e-04 2.23204484e-12]\n",
      " [9.99195039e-01 8.04992160e-04 4.43309209e-11]\n",
      " [9.99554813e-01 4.45223122e-04 1.02920329e-11]\n",
      " [9.41834116e-07 7.78821930e-02 9.22116876e-01]\n",
      " [1.24373046e-05 2.28720590e-01 7.71266937e-01]\n",
      " [3.99656165e-06 1.45571604e-01 8.54424417e-01]\n",
      " [9.98611808e-01 1.38820929e-03 1.73208517e-10]\n",
      " [4.43628617e-03 9.62907016e-01 3.26567143e-02]\n",
      " [1.47974388e-08 1.97225977e-02 9.80277359e-01]\n",
      " [6.03560265e-03 9.54696536e-01 3.92678790e-02]\n",
      " [9.99973893e-01 2.60607867e-05 1.91164765e-14]\n",
      " [6.11165422e-04 7.18167067e-01 2.81221718e-01]\n",
      " [1.18582731e-03 8.42660129e-01 1.56154022e-01]\n",
      " [9.90457118e-01 9.54292621e-03 6.66138078e-09]\n",
      " [9.99911308e-01 8.87244460e-05 2.91721969e-13]\n",
      " [7.33457273e-05 4.21924353e-01 5.78002274e-01]\n",
      " [1.01854203e-04 5.09771287e-01 4.90126789e-01]\n",
      " [6.02162686e-07 7.31618032e-02 9.26837623e-01]\n",
      " [1.04070030e-04 4.55636859e-01 5.44259071e-01]\n",
      " [8.47501997e-06 1.82481527e-01 8.17509949e-01]\n",
      " [5.70467546e-06 1.87993452e-01 8.12000871e-01]\n",
      " [1.43303487e-06 8.54136422e-02 9.14584935e-01]\n",
      " [9.99282181e-01 7.17871764e-04 2.61781638e-11]\n",
      " [2.30324510e-02 9.68501627e-01 8.46596994e-03]\n",
      " [4.05474020e-06 1.42214134e-01 8.57781827e-01]\n",
      " [9.79771372e-04 8.69518638e-01 1.29501626e-01]\n",
      " [9.98871386e-01 1.12856587e-03 8.72440592e-11]\n",
      " [1.13912136e-03 8.37942898e-01 1.60917908e-01]\n",
      " [8.26922314e-06 1.94226593e-01 8.05765152e-01]\n",
      " [2.16754943e-05 3.22806001e-01 6.77172363e-01]\n",
      " [9.99040425e-01 9.59596073e-04 4.83235570e-11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 1, 2, 0, 0, 0, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 1, 0, 0, 0,\n",
       "       2, 2, 2, 0, 1, 2, 1, 0, 1, 1, 0, 0, 2, 1, 2, 2, 2, 2, 2, 0, 1, 2,\n",
       "       1, 0, 1, 2, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test 샘플들의 클래스 예측하기\n",
    "y_prob = model.predict(X_test)    # X_test의 출력값 확인하기\n",
    "print(y_prob)\n",
    "\n",
    "y_class = y_prob.argmax(axis=-1)  # X_test의 클래스 예측하기\n",
    "y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34Xez1yYLtV0",
    "outputId": "6707f78b-2b13-440b-ff75-dae7df68814b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.7, 3.8, 1.7, 0.3]\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "[[9.9981922e-01 1.8085196e-04 9.2170195e-13]] 0\n"
     ]
    }
   ],
   "source": [
    "# 새로운 샘플의 클래스 예측하기\n",
    "X_new = [5.7, 3.8, 1.7, 0.3]\n",
    "print(X_new)\n",
    "\n",
    "y_prob = model.predict([X_new]) # X_new의 출력값 확인하기\n",
    "y_pred = y_prob.argmax()        # X_new의 클래스 예측하기\n",
    "print(y_prob, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDjOYxUzLtVz",
    "outputId": "933c11a6-e82d-4da2-a5d0-b00254863d9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iOdX9FRmLtVz",
    "outputId": "f42901a2-1152-4b9c-d490-121837488b9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "100           5.7          3.8           1.7          0.3\n",
       "101           7.2          3.6           6.1          2.5\n",
       "102           6.3          2.9           5.6          1.8\n",
       "103           4.9          2.4           3.3          1.0\n",
       "104           7.7          3.0           6.1          2.3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaOIG8Kaovrc",
    "outputId": "f7db397c-0901-436d-a563-225bd00b921a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 101, 102, 103, 104]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(5).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfXV29CxuGk0",
    "outputId": "5721db06-0c81-4c3f-fe2e-06d9366e9a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length    5.7\n",
      "sepal_width     3.8\n",
      "petal_length    1.7\n",
      "petal_width     0.3\n",
      "Name: 100, dtype: float64\n",
      "\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "[[9.9981922e-01 1.8085196e-04 9.2170195e-13]] 0\n"
     ]
    }
   ],
   "source": [
    "X_test0 = X_test.loc[100]\n",
    "print(X_test0); print()\n",
    "\n",
    "X_test_li = list(X_test0)\n",
    "y_prob = model.predict([X_test_li])  # model.predict([[5.7, 3.8, 1.7, 0.3]])\n",
    "y_pred = y_prob.argmax()\n",
    "print(y_prob, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "flB-FoC2LtV0"
   },
   "outputs": [],
   "source": [
    "def predict_iris(X_new):\n",
    "  y_prob = model.predict([X_new])\n",
    "  y_pred = y_prob.argmax()\n",
    "  print(X_new, y_prob, y_pred, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMJdeu5nLtV0",
    "outputId": "94677c6e-8a7d-44e1-d456-8f64aae8e70d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step\n",
      "[5.770000000000001, 3.019, 3.6839999999999997, 1.1649999999999998]\t[[0.04643844 0.9504568  0.00310478]]\t1\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "[4.3, 2.0, 1.1, 0.1]\t[[9.9348408e-01 6.5159490e-03 2.7567377e-09]]\t0\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "[7.7, 4.1, 6.7, 2.5]\t[[3.6158394e-07 5.6502569e-02 9.4349706e-01]]\t2\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "[4.3, 4.1, 1.1, 2.5]\t[[7.5640410e-01 2.4356766e-01 2.8197981e-05]]\t0\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "[7.7, 2.0, 6.7, 0.1]\t[[1.4719424e-04 8.4301466e-01 1.5683809e-01]]\t1\n"
     ]
    }
   ],
   "source": [
    "X_mean = [X_train[\"sepal_length\"].mean(), X_train[\"sepal_width\"].mean(), X_train[\"petal_length\"].mean(), X_train[\"petal_width\"].mean()]\n",
    "X_min = [X_train[\"sepal_length\"].min(), X_train[\"sepal_width\"].min(), X_train[\"petal_length\"].min(), X_train[\"petal_width\"].min()]\n",
    "X_max = [X_train[\"sepal_length\"].max(), X_train[\"sepal_width\"].max(), X_train[\"petal_length\"].max(), X_train[\"petal_width\"].max()]\n",
    "X_min_max = [X_train[\"sepal_length\"].min(), X_train[\"sepal_width\"].max(), X_train[\"petal_length\"].min(), X_train[\"petal_width\"].max()]\n",
    "X_max_min = [X_train[\"sepal_length\"].max(), X_train[\"sepal_width\"].min(), X_train[\"petal_length\"].max(), X_train[\"petal_width\"].min()]\n",
    "\n",
    "predict_iris(X_mean)\n",
    "predict_iris(X_min)\n",
    "predict_iris(X_max)\n",
    "predict_iris(X_min_max)\n",
    "predict_iris(X_max_min)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
