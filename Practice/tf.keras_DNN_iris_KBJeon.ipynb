{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "     ---------------------------------------- 455.9/455.9 MB 241.7 kB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 462.4 kB/s eta 0:00:00\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "     ---------------------------------------- 5.9/5.9 MB 701.4 kB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "     ---------------------------------------- 123.4/123.4 kB 516.5 kB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "     ---------------------------------------- 438.7/438.7 kB 638.5 kB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     ---------------------------------------- 895.9/895.9 kB 623.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (1.22.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 628.9 kB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "     ---------------------------------------- 14.2/14.2 MB 196.6 kB/s eta 0:00:00\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 161.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 587.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 302.8 kB/s eta 0:00:00\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.6/42.6 kB 159.3 kB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.49.1-cp39-cp39-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 297.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ---------------------------------------- 781.3/781.3 kB 146.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.25.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n",
      "     ---------------------------------------- 169.8/169.8 kB 83.6 kB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.3/93.3 kB 161.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     ---------------------------------------- 155.3/155.3 kB 309.2 kB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB 608.2 kB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 151.7/151.7 kB 312.2 kB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, keras-preprocessing, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.9.24 gast-0.4.0 google-auth-2.12.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.49.1 h5py-3.7.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.1 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 wrapt-1.14.1\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "     ---------------------------------------- 455.9/455.9 MB 605.3 kB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (1.22.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.49.1-cp39-cp39-win_amd64.whl (3.6 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.25.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kbum0\\miniconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, keras-preprocessing, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.9.24 gast-0.4.0 google-auth-2.12.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.49.1 h5py-3.7.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.1 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "22UZuhWkLtVt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers  # 모듈(변수나 함수를 포함)만 불러오기\n",
    "\n",
    "# iris 데이터를 읽기\n",
    "df = pd.read_csv(\"iris.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "3GAFF1QOk58E",
    "outputId": "333e58a1-4a26-4f5e-b366-a5efc04501b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>iris_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width        iris_type\n",
       "0             6.4          3.1           5.5          1.8   Iris-virginica\n",
       "1             6.5          3.0           5.8          2.2   Iris-virginica\n",
       "2             4.6          3.1           1.5          0.2      Iris-setosa\n",
       "3             6.4          2.8           5.6          2.1   Iris-virginica\n",
       "4             5.0          3.3           1.4          0.2      Iris-setosa\n",
       "..            ...          ...           ...          ...              ...\n",
       "145           5.1          3.8           1.9          0.4      Iris-setosa\n",
       "146           5.7          2.8           4.5          1.3  Iris-versicolor\n",
       "147           6.9          3.1           5.4          2.1   Iris-virginica\n",
       "148           7.2          3.0           5.8          1.6   Iris-virginica\n",
       "149           4.9          3.0           1.4          0.2      Iris-setosa\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sepal_length  sepal_width  petal_length  petal_width\n",
      "iris_type                                                            \n",
      "Iris-setosa                50           50            50           50\n",
      "Iris-versicolor            50           50            50           50\n",
      "Iris-virginica             50           50            50           50\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('iris_type').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WaC6EJH_kwwz"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:4]\n",
    "\n",
    "# 레이블링, 라벨링 (labelling) => one-hot encoding\n",
    "bclass = {\"Iris-setosa\":[1,0,0], \"Iris-versicolor\":[0,1,0], \"Iris-virginica\":[0,0,1]}\n",
    "y = np.empty((150,3))     # 150x3 크기의 다차원 벡터 생성\n",
    "for i, v in enumerate(df[\"iris_type\"]):\n",
    "    y[i] = bclass[v]        # \"Iris-setosa\"이면, y[i]=[1,0,0] 와 같이 할당\n",
    "    \n",
    "# 훈련 전용 데이터와 테스트 전용 데이터로 나누기\n",
    "X_train, y_train = X[0:100], y[0:100]\n",
    "X_test,  y_test  = X[100:150], y[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "G2UgYhccLtVu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 구조 정의하기\n",
    "model = tf.keras.Sequential()         # 순차적 계층화 준비\n",
    "model.add(layers.Dense(10, input_shape=(4,)))  # 입력 4개로부터 전달받는 10개 노드의 layer 생성\n",
    "model.add(layers.Activation('relu'))  # 활성화함수 채택(hidden layer)\n",
    "model.add(layers.Dropout(0.1))        # dropout ratio=10% (배치 훈련시 10% arc 무시)\n",
    "\n",
    "model.add(layers.Dense(8))            # 8개 노드의 layer 생성\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Dense(3))\n",
    "model.add(layers.Activation('softmax'))# 분류(classification)을 위해 softmax 함수 사용\n",
    "\n",
    "# 모델 구축하기\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # 다중 교차엔트로피\n",
    "    optimizer=\"rmsprop\",   # 최적화 기법 중 하나\n",
    "    metrics=['accuracy'])  # 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IhHchdXLtVv",
    "outputId": "bc0045b9-353e-4f65-ec94-d7b114c8f41e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 68ms/step - loss: 2.2105 - accuracy: 0.3667 - val_loss: 2.1388 - val_accuracy: 0.1000\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9746 - accuracy: 0.3667 - val_loss: 2.0090 - val_accuracy: 0.1000\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.7701 - accuracy: 0.3667 - val_loss: 1.9076 - val_accuracy: 0.1000\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5954 - accuracy: 0.3667 - val_loss: 1.8255 - val_accuracy: 0.1000\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6761 - accuracy: 0.3556 - val_loss: 1.7346 - val_accuracy: 0.1000\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6790 - accuracy: 0.3889 - val_loss: 1.6486 - val_accuracy: 0.1000\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.5341 - accuracy: 0.3556 - val_loss: 1.5801 - val_accuracy: 0.1000\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4320 - accuracy: 0.3778 - val_loss: 1.5081 - val_accuracy: 0.1000\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4402 - accuracy: 0.3667 - val_loss: 1.4380 - val_accuracy: 0.1000\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3964 - accuracy: 0.3889 - val_loss: 1.3712 - val_accuracy: 0.1000\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2751 - accuracy: 0.3778 - val_loss: 1.3203 - val_accuracy: 0.1000\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2056 - accuracy: 0.3667 - val_loss: 1.2686 - val_accuracy: 0.1000\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2222 - accuracy: 0.3778 - val_loss: 1.2170 - val_accuracy: 0.1000\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1850 - accuracy: 0.3889 - val_loss: 1.1699 - val_accuracy: 0.1000\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0526 - accuracy: 0.4222 - val_loss: 1.1414 - val_accuracy: 0.1000\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0420 - accuracy: 0.4222 - val_loss: 1.1154 - val_accuracy: 0.1000\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0998 - accuracy: 0.3889 - val_loss: 1.0789 - val_accuracy: 0.1000\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0240 - accuracy: 0.3778 - val_loss: 1.0453 - val_accuracy: 0.1000\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0083 - accuracy: 0.3778 - val_loss: 1.0189 - val_accuracy: 0.1000\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0239 - accuracy: 0.3889 - val_loss: 0.9963 - val_accuracy: 0.1000\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0066 - accuracy: 0.4111 - val_loss: 0.9797 - val_accuracy: 0.1000\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9858 - accuracy: 0.4000 - val_loss: 0.9617 - val_accuracy: 0.2000\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9324 - accuracy: 0.4333 - val_loss: 0.9394 - val_accuracy: 0.2000\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9496 - accuracy: 0.3778 - val_loss: 0.9188 - val_accuracy: 0.3000\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9248 - accuracy: 0.5111 - val_loss: 0.9075 - val_accuracy: 0.2000\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9467 - accuracy: 0.4000 - val_loss: 0.8791 - val_accuracy: 0.4000\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9171 - accuracy: 0.4667 - val_loss: 0.8620 - val_accuracy: 0.6000\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9285 - accuracy: 0.5222 - val_loss: 0.8482 - val_accuracy: 0.7000\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9221 - accuracy: 0.5778 - val_loss: 0.8320 - val_accuracy: 0.8000\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8755 - accuracy: 0.6333 - val_loss: 0.8134 - val_accuracy: 1.0000\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8811 - accuracy: 0.6556 - val_loss: 0.7985 - val_accuracy: 1.0000\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8862 - accuracy: 0.7111 - val_loss: 0.7847 - val_accuracy: 1.0000\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8660 - accuracy: 0.7111 - val_loss: 0.7666 - val_accuracy: 1.0000\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8374 - accuracy: 0.6778 - val_loss: 0.7585 - val_accuracy: 1.0000\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8318 - accuracy: 0.7444 - val_loss: 0.7394 - val_accuracy: 1.0000\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8138 - accuracy: 0.7444 - val_loss: 0.7225 - val_accuracy: 1.0000\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8576 - accuracy: 0.6444 - val_loss: 0.7096 - val_accuracy: 1.0000\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8097 - accuracy: 0.7556 - val_loss: 0.7019 - val_accuracy: 1.0000\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7581 - accuracy: 0.7556 - val_loss: 0.6827 - val_accuracy: 1.0000\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8378 - accuracy: 0.6778 - val_loss: 0.6771 - val_accuracy: 1.0000\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7791 - accuracy: 0.7556 - val_loss: 0.6612 - val_accuracy: 1.0000\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.7215 - accuracy: 0.8667 - val_loss: 0.6397 - val_accuracy: 1.0000\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7400 - accuracy: 0.8222 - val_loss: 0.6206 - val_accuracy: 1.0000\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7908 - accuracy: 0.7444 - val_loss: 0.6120 - val_accuracy: 1.0000\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7167 - accuracy: 0.7444 - val_loss: 0.5989 - val_accuracy: 1.0000\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7257 - accuracy: 0.7778 - val_loss: 0.5871 - val_accuracy: 1.0000\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7113 - accuracy: 0.8000 - val_loss: 0.5769 - val_accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6899 - accuracy: 0.8111 - val_loss: 0.5651 - val_accuracy: 1.0000\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7515 - accuracy: 0.7333 - val_loss: 0.5403 - val_accuracy: 1.0000\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6665 - accuracy: 0.8111 - val_loss: 0.5354 - val_accuracy: 1.0000\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7379 - accuracy: 0.6667 - val_loss: 0.5166 - val_accuracy: 1.0000\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6666 - accuracy: 0.7889 - val_loss: 0.4990 - val_accuracy: 1.0000\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6944 - accuracy: 0.7333 - val_loss: 0.4831 - val_accuracy: 1.0000\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6999 - accuracy: 0.7333 - val_loss: 0.4712 - val_accuracy: 1.0000\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6437 - accuracy: 0.7889 - val_loss: 0.4557 - val_accuracy: 1.0000\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6193 - accuracy: 0.7889 - val_loss: 0.4445 - val_accuracy: 1.0000\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6147 - accuracy: 0.8333 - val_loss: 0.4329 - val_accuracy: 1.0000\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6358 - accuracy: 0.7556 - val_loss: 0.4193 - val_accuracy: 1.0000\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5705 - accuracy: 0.8222 - val_loss: 0.4095 - val_accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6420 - accuracy: 0.7333 - val_loss: 0.4085 - val_accuracy: 1.0000\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6093 - accuracy: 0.7778 - val_loss: 0.4025 - val_accuracy: 1.0000\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5918 - accuracy: 0.7667 - val_loss: 0.3946 - val_accuracy: 1.0000\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5686 - accuracy: 0.7444 - val_loss: 0.3765 - val_accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6148 - accuracy: 0.7667 - val_loss: 0.3732 - val_accuracy: 1.0000\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5817 - accuracy: 0.7889 - val_loss: 0.3685 - val_accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6259 - accuracy: 0.7778 - val_loss: 0.3629 - val_accuracy: 1.0000\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5169 - accuracy: 0.8222 - val_loss: 0.3560 - val_accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5660 - accuracy: 0.8333 - val_loss: 0.3501 - val_accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5913 - accuracy: 0.7556 - val_loss: 0.3479 - val_accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5212 - accuracy: 0.8333 - val_loss: 0.3402 - val_accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5800 - accuracy: 0.7333 - val_loss: 0.3244 - val_accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5374 - accuracy: 0.8111 - val_loss: 0.3149 - val_accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5149 - accuracy: 0.8444 - val_loss: 0.3115 - val_accuracy: 1.0000\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5581 - accuracy: 0.8000 - val_loss: 0.3006 - val_accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4875 - accuracy: 0.8333 - val_loss: 0.2875 - val_accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5942 - accuracy: 0.7444 - val_loss: 0.2838 - val_accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4910 - accuracy: 0.8222 - val_loss: 0.2789 - val_accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5239 - accuracy: 0.7889 - val_loss: 0.2751 - val_accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4512 - accuracy: 0.9000 - val_loss: 0.2723 - val_accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4798 - accuracy: 0.8000 - val_loss: 0.2625 - val_accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5081 - accuracy: 0.8222 - val_loss: 0.2593 - val_accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4597 - accuracy: 0.8556 - val_loss: 0.2545 - val_accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5151 - accuracy: 0.8222 - val_loss: 0.2457 - val_accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5206 - accuracy: 0.7667 - val_loss: 0.2475 - val_accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5367 - accuracy: 0.7778 - val_loss: 0.2407 - val_accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4677 - accuracy: 0.8778 - val_loss: 0.2342 - val_accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4295 - accuracy: 0.8889 - val_loss: 0.2278 - val_accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4753 - accuracy: 0.7778 - val_loss: 0.2235 - val_accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5280 - accuracy: 0.7889 - val_loss: 0.2240 - val_accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5194 - accuracy: 0.7667 - val_loss: 0.2177 - val_accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4341 - accuracy: 0.8556 - val_loss: 0.2108 - val_accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4606 - accuracy: 0.8222 - val_loss: 0.2082 - val_accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4373 - accuracy: 0.8556 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4714 - accuracy: 0.8333 - val_loss: 0.2082 - val_accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4586 - accuracy: 0.8556 - val_loss: 0.2064 - val_accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4747 - accuracy: 0.7778 - val_loss: 0.2002 - val_accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4458 - accuracy: 0.8111 - val_loss: 0.1987 - val_accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4797 - accuracy: 0.7667 - val_loss: 0.1932 - val_accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3910 - accuracy: 0.8889 - val_loss: 0.1884 - val_accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3913 - accuracy: 0.8889 - val_loss: 0.1813 - val_accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4012 - accuracy: 0.8778 - val_loss: 0.1760 - val_accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5072 - accuracy: 0.7667 - val_loss: 0.1734 - val_accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4295 - accuracy: 0.8222 - val_loss: 0.1774 - val_accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3843 - accuracy: 0.8889 - val_loss: 0.1731 - val_accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4221 - accuracy: 0.7889 - val_loss: 0.1702 - val_accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3810 - accuracy: 0.8556 - val_loss: 0.1646 - val_accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4101 - accuracy: 0.7778 - val_loss: 0.1616 - val_accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3846 - accuracy: 0.8444 - val_loss: 0.1611 - val_accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4663 - accuracy: 0.8333 - val_loss: 0.1587 - val_accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3906 - accuracy: 0.8444 - val_loss: 0.1530 - val_accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4296 - accuracy: 0.8556 - val_loss: 0.1519 - val_accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4249 - accuracy: 0.8444 - val_loss: 0.1505 - val_accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3909 - accuracy: 0.8778 - val_loss: 0.1477 - val_accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4778 - accuracy: 0.7889 - val_loss: 0.1497 - val_accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3347 - accuracy: 0.8778 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3626 - accuracy: 0.8556 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3475 - accuracy: 0.8556 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4288 - accuracy: 0.8333 - val_loss: 0.1418 - val_accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3861 - accuracy: 0.8333 - val_loss: 0.1409 - val_accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3828 - accuracy: 0.8556 - val_loss: 0.1388 - val_accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3869 - accuracy: 0.8556 - val_loss: 0.1326 - val_accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3468 - accuracy: 0.9222 - val_loss: 0.1294 - val_accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4495 - accuracy: 0.7889 - val_loss: 0.1290 - val_accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3395 - accuracy: 0.8889 - val_loss: 0.1268 - val_accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3620 - accuracy: 0.8556 - val_loss: 0.1225 - val_accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3233 - accuracy: 0.8778 - val_loss: 0.1269 - val_accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3660 - accuracy: 0.8667 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3777 - accuracy: 0.8556 - val_loss: 0.1219 - val_accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3498 - accuracy: 0.8333 - val_loss: 0.1177 - val_accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3791 - accuracy: 0.8778 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3425 - accuracy: 0.9000 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3361 - accuracy: 0.8556 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3968 - accuracy: 0.7778 - val_loss: 0.1134 - val_accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2979 - accuracy: 0.9000 - val_loss: 0.1121 - val_accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3808 - accuracy: 0.8222 - val_loss: 0.1113 - val_accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3646 - accuracy: 0.8333 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3094 - accuracy: 0.8667 - val_loss: 0.1053 - val_accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3747 - accuracy: 0.8222 - val_loss: 0.1027 - val_accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3012 - accuracy: 0.9222 - val_loss: 0.1004 - val_accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3238 - accuracy: 0.8778 - val_loss: 0.0990 - val_accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3359 - accuracy: 0.8667 - val_loss: 0.0995 - val_accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3427 - accuracy: 0.8111 - val_loss: 0.1015 - val_accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3083 - accuracy: 0.9000 - val_loss: 0.0980 - val_accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3273 - accuracy: 0.8667 - val_loss: 0.0959 - val_accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3076 - accuracy: 0.8889 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3048 - accuracy: 0.8889 - val_loss: 0.0955 - val_accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3269 - accuracy: 0.8444 - val_loss: 0.0945 - val_accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3280 - accuracy: 0.8778 - val_loss: 0.0913 - val_accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3213 - accuracy: 0.8889 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3455 - accuracy: 0.8444 - val_loss: 0.0884 - val_accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3417 - accuracy: 0.8667 - val_loss: 0.0861 - val_accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2682 - accuracy: 0.9333 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3454 - accuracy: 0.8556 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3400 - accuracy: 0.8778 - val_loss: 0.0812 - val_accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3246 - accuracy: 0.8222 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2324 - accuracy: 0.9444 - val_loss: 0.0815 - val_accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2745 - accuracy: 0.9111 - val_loss: 0.0789 - val_accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3424 - accuracy: 0.8778 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2630 - accuracy: 0.9111 - val_loss: 0.0797 - val_accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3491 - accuracy: 0.8556 - val_loss: 0.0786 - val_accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2996 - accuracy: 0.8889 - val_loss: 0.0814 - val_accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3451 - accuracy: 0.8778 - val_loss: 0.0807 - val_accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2845 - accuracy: 0.9111 - val_loss: 0.0787 - val_accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2744 - accuracy: 0.9000 - val_loss: 0.0774 - val_accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3340 - accuracy: 0.8556 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3320 - accuracy: 0.8667 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2439 - accuracy: 0.9333 - val_loss: 0.0721 - val_accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2631 - accuracy: 0.9000 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2578 - accuracy: 0.9222 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2519 - accuracy: 0.9111 - val_loss: 0.0691 - val_accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3743 - accuracy: 0.8556 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2903 - accuracy: 0.8778 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2531 - accuracy: 0.9111 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3368 - accuracy: 0.8778 - val_loss: 0.0652 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3608 - accuracy: 0.8333 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3005 - accuracy: 0.9111 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2980 - accuracy: 0.9111 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2929 - accuracy: 0.9111 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2978 - accuracy: 0.8889 - val_loss: 0.0666 - val_accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2549 - accuracy: 0.9000 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3031 - accuracy: 0.8889 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2843 - accuracy: 0.8778 - val_loss: 0.0664 - val_accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2769 - accuracy: 0.8778 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2219 - accuracy: 0.9333 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2290 - accuracy: 0.9333 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2314 - accuracy: 0.9444 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3374 - accuracy: 0.8778 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2751 - accuracy: 0.9000 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2345 - accuracy: 0.9111 - val_loss: 0.0587 - val_accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2707 - accuracy: 0.8778 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2478 - accuracy: 0.9000 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3088 - accuracy: 0.9000 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2469 - accuracy: 0.9222 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2842 - accuracy: 0.9000 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2701 - accuracy: 0.8778 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2707 - accuracy: 0.9000 - val_loss: 0.0614 - val_accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2407 - accuracy: 0.9222 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2396 - accuracy: 0.9333 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1791 - accuracy: 0.9778 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2919 - accuracy: 0.9000 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2051 - accuracy: 0.9444 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2853 - accuracy: 0.8556 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2380 - accuracy: 0.9222 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2951 - accuracy: 0.9222 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2574 - accuracy: 0.9111 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3402 - accuracy: 0.8222 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2494 - accuracy: 0.9222 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2692 - accuracy: 0.9111 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2197 - accuracy: 0.9556 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2424 - accuracy: 0.9111 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2486 - accuracy: 0.9000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2813 - accuracy: 0.8889 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2530 - accuracy: 0.9222 - val_loss: 0.0565 - val_accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2589 - accuracy: 0.9000 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2673 - accuracy: 0.9000 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1980 - accuracy: 0.9333 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2150 - accuracy: 0.9111 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2085 - accuracy: 0.9444 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2341 - accuracy: 0.9222 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1862 - accuracy: 0.9556 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1509 - accuracy: 0.9778 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1927 - accuracy: 0.9556 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2195 - accuracy: 0.9333 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3201 - accuracy: 0.8778 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1742 - accuracy: 0.9222 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2742 - accuracy: 0.8778 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2703 - accuracy: 0.8889 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3140 - accuracy: 0.8444 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1952 - accuracy: 0.9444 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2195 - accuracy: 0.9444 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2150 - accuracy: 0.9111 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2751 - accuracy: 0.8778 - val_loss: 0.0418 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2184 - accuracy: 0.9222 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1896 - accuracy: 0.9667 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3257 - accuracy: 0.8667 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2221 - accuracy: 0.9000 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2196 - accuracy: 0.9000 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2606 - accuracy: 0.9222 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2275 - accuracy: 0.9000 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1771 - accuracy: 0.9667 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1724 - accuracy: 0.9444 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2262 - accuracy: 0.9111 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2135 - accuracy: 0.9111 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1895 - accuracy: 0.9333 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2585 - accuracy: 0.9111 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2314 - accuracy: 0.9222 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1497 - accuracy: 0.9778 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2356 - accuracy: 0.9222 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2111 - accuracy: 0.9222 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2158 - accuracy: 0.9333 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2160 - accuracy: 0.9000 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1911 - accuracy: 0.9444 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1821 - accuracy: 0.9444 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2439 - accuracy: 0.9000 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1477 - accuracy: 0.9778 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2323 - accuracy: 0.9333 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2424 - accuracy: 0.9000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2063 - accuracy: 0.9111 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2000 - accuracy: 0.9222 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2278 - accuracy: 0.9333 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1801 - accuracy: 0.9444 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2249 - accuracy: 0.9111 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1757 - accuracy: 0.9222 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2229 - accuracy: 0.8889 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1999 - accuracy: 0.9222 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2116 - accuracy: 0.9000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2019 - accuracy: 0.9222 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2530 - accuracy: 0.9000 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2215 - accuracy: 0.9111 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1629 - accuracy: 0.9444 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1787 - accuracy: 0.9556 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2458 - accuracy: 0.9111 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1755 - accuracy: 0.9444 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2192 - accuracy: 0.9222 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1715 - accuracy: 0.9444 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2024 - accuracy: 0.9222 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3054 - accuracy: 0.8556 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1296 - accuracy: 0.9778 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1209 - accuracy: 0.9778 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2724 - accuracy: 0.8778 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2122 - accuracy: 0.9222 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1684 - accuracy: 0.9444 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1398 - accuracy: 0.9556 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1811 - accuracy: 0.9333 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1308 - accuracy: 0.9556 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1794 - accuracy: 0.9444 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1631 - accuracy: 0.9556 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1334 - accuracy: 0.9556 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2776 - accuracy: 0.8556 - val_loss: 0.0282 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1812 - accuracy: 0.9556 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1527 - accuracy: 0.9778 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1833 - accuracy: 0.9111 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1979 - accuracy: 0.9222 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2108 - accuracy: 0.9333 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1508 - accuracy: 0.9556 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1403 - accuracy: 0.9556 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1485 - accuracy: 0.9222 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1679 - accuracy: 0.9444 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1519 - accuracy: 0.9444 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9800\n",
      "test_loss:  0.08542028069496155\n",
      "test_acc:  0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "# 데이터 훈련하기\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=20,     # 20개에 한 번씩 업데이터 실행\n",
    "    epochs=300,          # 전체 훈련 데이터셋을 총 200회 반복 실험. 단, 조기중지될 수 있음\n",
    "    validation_split=0.1,  \n",
    "        #validation data 분할 비율. 즉, 150개 중에서 20%인 30개를 validation용으로 분할\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)],  \n",
    "        #'val_loss'를 monitor하여 감소하면 10번 더 참고 조기중지(early stopping)\n",
    "    verbose=1)   # 전 과정을 화면에 출력(1) 또는 미출력(0) 모드\n",
    "\n",
    "# 테스트 데이터로 평가하기\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('test_loss: ', score[0])\n",
    "print('test_acc: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVZ2sf6Gb5Y-",
    "outputId": "e18e011e-5e3c-4b6d-9556-34d0db422f9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "Hh1NwcAwLtVw",
    "outputId": "828e6f60-2f2e-4576-dc99-53eddbc4066d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0LNN770LtVw",
    "outputId": "1d0a5184-5bb0-47e9-e5d4-5ac09faef69c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                50        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 10)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165\n",
      "Trainable params: 165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ap06VxZI5Aog",
    "outputId": "be69fe44-d828-4e2b-8e2e-8fabb0ee181a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.2906744 ,  0.20027333, -0.09110651, -0.60207444,  0.15214339,\n",
       "         -0.4301924 , -0.60816073, -0.26213235,  0.6895543 , -0.45601502],\n",
       "        [ 0.54453254, -0.5600072 ,  0.50968766,  0.04366291,  0.14322282,\n",
       "          0.06732392, -0.00551718, -0.4466532 , -0.20914352, -0.02457726],\n",
       "        [-0.47508016,  0.45307076,  0.08309688, -0.5701083 ,  0.575024  ,\n",
       "         -0.3201179 ,  0.20277983,  0.49688366, -0.74307024, -0.50831294],\n",
       "        [ 0.39955804,  0.15031072, -0.67558867,  0.64978147,  0.7959674 ,\n",
       "         -0.20745304,  0.42022705,  0.64993733, -0.19547282,  0.50637305]],\n",
       "       dtype=float32),\n",
       " array([-0.07678263, -0.04965587,  0.04799657,  0.        , -0.13355534,\n",
       "         0.        ,  0.        , -0.27990985,  0.30662775,  0.        ],\n",
       "       dtype=float32),\n",
       " array([[ 0.4796396 , -0.09097292, -0.27306366, -0.07225899,  0.08957896,\n",
       "          0.5521901 , -0.42894208, -0.21050495],\n",
       "        [ 1.0201339 , -0.21277097, -0.0750156 ,  1.2054231 , -0.33289698,\n",
       "          0.08639468,  0.12554175,  0.21287678],\n",
       "        [-0.61106735,  0.532304  ,  0.39334387, -0.84114206,  0.98149633,\n",
       "          0.64127225, -0.26598233, -0.07502254],\n",
       "        [-0.21540609,  0.36942703, -0.37687957, -0.02456027, -0.30544308,\n",
       "          0.534495  , -0.22323692, -0.51733273],\n",
       "        [ 0.54769486,  0.05720597,  0.07146795,  0.5090184 ,  0.13108242,\n",
       "          0.01247675, -0.51634306, -0.42728353],\n",
       "        [-0.20827508,  0.4621737 , -0.45844263,  0.55310845, -0.06161672,\n",
       "          0.07810211,  0.484735  , -0.4004991 ],\n",
       "        [-0.14430356,  0.06278002, -0.5088799 ,  0.28486496, -0.1994273 ,\n",
       "          0.1691215 ,  0.27365118, -0.14706898],\n",
       "        [ 0.6907265 , -0.44222108, -0.862521  ,  0.9156125 , -0.7928417 ,\n",
       "         -0.85858077, -0.4206036 , -0.64463246],\n",
       "        [-0.57305247,  0.695217  ,  0.71542245, -0.18733753,  1.2279623 ,\n",
       "          1.2260072 , -0.31082276,  0.43733022],\n",
       "        [-0.02466184,  0.06675428, -0.39306414,  0.30391008,  0.20354074,\n",
       "         -0.24641997, -0.01996517,  0.5499896 ]], dtype=float32),\n",
       " array([-0.12082303,  0.23056147,  0.35512334, -0.12612772,  0.16176993,\n",
       "         0.25710383, -0.08074854, -0.00133952], dtype=float32),\n",
       " array([[-1.0758456 ,  0.13341464,  0.34789145],\n",
       "        [ 0.89326686, -0.10660997, -0.94359344],\n",
       "        [ 0.62834275,  0.3273754 , -0.8037561 ],\n",
       "        [-1.2217283 , -0.18809788,  0.01543833],\n",
       "        [ 0.4936611 ,  0.10944261, -1.055915  ],\n",
       "        [ 0.7238953 ,  0.6741929 , -1.47824   ],\n",
       "        [ 0.38733944, -0.55072594,  0.07513504],\n",
       "        [-0.19346926,  0.60367256, -0.52264345]], dtype=float32),\n",
       " array([-0.07592595, -0.11031538,  0.17005338], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhPK4V6nLtVx",
    "outputId": "c191a145-aeb2-43de-dcab-c9a5229e7888",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                50        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 10)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165\n",
      "Trainable params: 165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9800\n",
      "test_loss:  0.08542028069496155\n",
      "test_acc:  0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "model.save(\"dnn_iris.h5\")\n",
    "print(\"Saved model to disk.\")\n",
    "\n",
    "from numpy import loadtxt\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "# 저장된 모델 읽어오기\n",
    "loaded_model = load_model(\"dnn_iris.h5\")\n",
    "model.summary()\n",
    "\n",
    "# 모델을 평가하기\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('test_loss: ', score[0])\n",
    "print('test_acc: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8sQr21XLtVy",
    "outputId": "d5a57154-8a71-4852-dfa8-2d744b50db50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "[[9.95122612e-01 4.87736380e-03 6.08401732e-11]\n",
      " [5.76062886e-09 3.84393148e-02 9.61560667e-01]\n",
      " [8.11175696e-08 6.44459501e-02 9.35553968e-01]\n",
      " [1.37895131e-02 9.78680730e-01 7.52975885e-03]\n",
      " [2.02644324e-09 3.27544697e-02 9.67245519e-01]\n",
      " [9.93057609e-01 6.94243424e-03 2.91734137e-10]\n",
      " [9.93078530e-01 6.92143617e-03 2.37541709e-10]\n",
      " [9.97407138e-01 2.59289029e-03 2.25007990e-12]\n",
      " [1.69461742e-07 6.58501461e-02 9.34149683e-01]\n",
      " [4.57799061e-08 5.32395914e-02 9.46760356e-01]\n",
      " [1.39628668e-04 8.58961701e-01 1.40898570e-01]\n",
      " [9.94495451e-01 5.50452387e-03 1.05825002e-10]\n",
      " [1.30460330e-03 9.71199334e-01 2.74961349e-02]\n",
      " [9.96137798e-01 3.86223919e-03 1.97577024e-11]\n",
      " [1.71533306e-04 9.80579078e-01 1.92494802e-02]\n",
      " [9.58736450e-08 1.16100028e-01 8.83899927e-01]\n",
      " [7.93535051e-08 5.70787601e-02 9.42921221e-01]\n",
      " [2.41545099e-03 9.92797315e-01 4.78730211e-03]\n",
      " [1.77907315e-03 9.86614406e-01 1.16065480e-02]\n",
      " [9.93647993e-01 6.35202462e-03 1.95209696e-10]\n",
      " [9.89742815e-01 1.02571668e-02 1.97306571e-09]\n",
      " [9.92186904e-01 7.81304855e-03 5.20699706e-10]\n",
      " [1.19565975e-08 4.29309383e-02 9.57069099e-01]\n",
      " [2.22923987e-07 1.05638906e-01 8.94360900e-01]\n",
      " [3.08663068e-08 5.01156375e-02 9.49884295e-01]\n",
      " [9.87535536e-01 1.24644237e-02 4.27580149e-09]\n",
      " [9.48634406e-04 9.93590236e-01 5.46111772e-03]\n",
      " [6.08270656e-11 1.90694202e-02 9.80930567e-01]\n",
      " [1.93769706e-03 9.68182266e-01 2.98800729e-02]\n",
      " [9.96303916e-01 3.69606144e-03 1.74333967e-11]\n",
      " [1.66964965e-04 7.12647557e-01 2.87185490e-01]\n",
      " [2.40402456e-04 7.96630740e-01 2.03128919e-01]\n",
      " [9.81999934e-01 1.80000793e-02 1.01862820e-08]\n",
      " [9.95230377e-01 4.76964191e-03 5.08347218e-11]\n",
      " [1.95888151e-06 2.07871482e-01 7.92126596e-01]\n",
      " [4.24091195e-06 3.70615870e-01 6.29379869e-01]\n",
      " [8.86773499e-09 6.07666224e-02 9.39233363e-01]\n",
      " [4.90893035e-06 2.64547080e-01 7.35448003e-01]\n",
      " [1.29764373e-07 6.14506416e-02 9.38549161e-01]\n",
      " [2.28898870e-07 2.73352265e-01 7.26647437e-01]\n",
      " [3.57961092e-08 5.06538600e-02 9.49346066e-01]\n",
      " [9.91546690e-01 8.45328066e-03 7.09034220e-10]\n",
      " [8.60316679e-03 9.87251043e-01 4.14575124e-03]\n",
      " [6.12558466e-08 6.67632595e-02 9.33236718e-01]\n",
      " [1.82462551e-04 9.78998005e-01 2.08196379e-02]\n",
      " [9.88967597e-01 1.10324305e-02 3.15787418e-09]\n",
      " [2.44930881e-04 8.34378779e-01 1.65376380e-01]\n",
      " [7.42509059e-08 7.05378279e-02 9.29462075e-01]\n",
      " [3.90634852e-07 2.15111092e-01 7.84888506e-01]\n",
      " [9.91341650e-01 8.65835231e-03 7.39008632e-10]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 1, 2, 0, 0, 0, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 1, 0, 0, 0,\n",
       "       2, 2, 2, 0, 1, 2, 1, 0, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2,\n",
       "       1, 0, 1, 2, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test 샘플들의 클래스 예측하기\n",
    "y_prob = model.predict(X_test)    # X_test의 출력값 확인하기\n",
    "print(y_prob)\n",
    "\n",
    "y_class = y_prob.argmax(axis=-1)  # X_test의 클래스 예측하기\n",
    "y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34Xez1yYLtV0",
    "outputId": "6707f78b-2b13-440b-ff75-dae7df68814b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.7, 3.8, 1.7, 0.3]\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "[[9.9512261e-01 4.8773685e-03 6.0840291e-11]] 0\n"
     ]
    }
   ],
   "source": [
    "# 새로운 샘플의 클래스 예측하기\n",
    "X_new = [5.7, 3.8, 1.7, 0.3]\n",
    "print(X_new)\n",
    "\n",
    "y_prob = model.predict([X_new]) # X_new의 출력값 확인하기\n",
    "y_pred = y_prob.argmax()        # X_new의 클래스 예측하기\n",
    "print(y_prob, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDjOYxUzLtVz",
    "outputId": "933c11a6-e82d-4da2-a5d0-b00254863d9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iOdX9FRmLtVz",
    "outputId": "f42901a2-1152-4b9c-d490-121837488b9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "100           5.7          3.8           1.7          0.3\n",
       "101           7.2          3.6           6.1          2.5\n",
       "102           6.3          2.9           5.6          1.8\n",
       "103           4.9          2.4           3.3          1.0\n",
       "104           7.7          3.0           6.1          2.3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaOIG8Kaovrc",
    "outputId": "f7db397c-0901-436d-a563-225bd00b921a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 101, 102, 103, 104]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(5).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfXV29CxuGk0",
    "outputId": "5721db06-0c81-4c3f-fe2e-06d9366e9a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length    5.7\n",
      "sepal_width     3.8\n",
      "petal_length    1.7\n",
      "petal_width     0.3\n",
      "Name: 100, dtype: float64\n",
      "\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[[9.9512261e-01 4.8773685e-03 6.0840291e-11]] 0\n"
     ]
    }
   ],
   "source": [
    "X_test0 = X_test.loc[100]\n",
    "print(X_test0); print()\n",
    "\n",
    "X_test_li = list(X_test0)\n",
    "y_prob = model.predict([X_test_li])  # model.predict([[5.7, 3.8, 1.7, 0.3]])\n",
    "y_pred = y_prob.argmax()\n",
    "print(y_prob, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "flB-FoC2LtV0"
   },
   "outputs": [],
   "source": [
    "def predict_iris(X_new):\n",
    "  y_prob = model.predict([X_new])\n",
    "  y_pred = y_prob.argmax()\n",
    "  print(X_new, y_prob, y_pred, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMJdeu5nLtV0",
    "outputId": "94677c6e-8a7d-44e1-d456-8f64aae8e70d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "[5.770000000000001, 3.019, 3.6839999999999997, 1.1649999999999998]\t[[0.01519255 0.9830635  0.00174388]]\t1\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "[4.3, 2.0, 1.1, 0.1]\t[[9.827776e-01 1.722242e-02 4.860667e-09]]\t0\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "[7.7, 4.1, 6.7, 2.5]\t[[5.3420384e-09 4.6360660e-02 9.5363933e-01]]\t2\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[4.3, 4.1, 1.1, 2.5]\t[[2.4956852e-01 7.5036609e-01 6.5378277e-05]]\t1\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "[7.7, 2.0, 6.7, 0.1]\t[[3.5805274e-06 8.5644025e-01 1.4355613e-01]]\t1\n"
     ]
    }
   ],
   "source": [
    "X_mean = [X_train[\"sepal_length\"].mean(), X_train[\"sepal_width\"].mean(), X_train[\"petal_length\"].mean(), X_train[\"petal_width\"].mean()]\n",
    "X_min = [X_train[\"sepal_length\"].min(), X_train[\"sepal_width\"].min(), X_train[\"petal_length\"].min(), X_train[\"petal_width\"].min()]\n",
    "X_max = [X_train[\"sepal_length\"].max(), X_train[\"sepal_width\"].max(), X_train[\"petal_length\"].max(), X_train[\"petal_width\"].max()]\n",
    "X_min_max = [X_train[\"sepal_length\"].min(), X_train[\"sepal_width\"].max(), X_train[\"petal_length\"].min(), X_train[\"petal_width\"].max()]\n",
    "X_max_min = [X_train[\"sepal_length\"].max(), X_train[\"sepal_width\"].min(), X_train[\"petal_length\"].max(), X_train[\"petal_width\"].min()]\n",
    "\n",
    "predict_iris(X_mean)\n",
    "predict_iris(X_min)\n",
    "predict_iris(X_max)\n",
    "predict_iris(X_min_max)\n",
    "predict_iris(X_max_min)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
