{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SWCON253] Machine Learning\n",
    "Teaching Assistant: Yeongwoong Kim (duddnd7575@khu.ac.kr)\n",
    "\n",
    "Professor: Hui Yong Kim (hykim.v@khu.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3:  Deep Learning Framwork: Pytorch를 이용하여 MLP 구현 (10점)\n",
    "\n",
    "### 학습목표\n",
    "- pytorch를 사용하여 구현된 MLP 구조를 이해하고 수정할수 있다.\n",
    "- Fashinon-MNIST 문제를 스스로 해결하면서 딥러닝 학습과정을 이해하고 하이퍼파라미터를 튜닝을 할 수 있다.\n",
    "\n",
    "### 실습내용\n",
    "pytorch를 사용하여 구현 되어 있는 MLP를 통해 Fashion-MNIST 데이터셋을 분류하는 classfier를 학습합니다.\n",
    "\n",
    "실습은 다음 순서로 진행됩니다.\n",
    "- 1) Fashon-MNIST 데이터셋 설명\n",
    "- 2) Data loading\n",
    "- 3) Multilayer Perceptron Model\n",
    "- 4) Training\n",
    "- 5) Evaluation\n",
    "- 6) Discussion\n",
    "\n",
    "아래 코드에는 2개의 퍼셉트론은 이용한 MLP 모델이 정의 되어 있습니다.\n",
    "실습을 시작하기전에 이 노트북 파일을 읽고 모든 셀을 실행해하여 올바르게 작동하는지 확인하세요.<br>\n",
    "이후에 아키텍쳐를 마음껏 변경하여 최고의 성능이 나오도록 수정해 보세요.\n",
    "\n",
    "**1. 다음은 변경 가능한 부분입니다.**\n",
    "- activation 함수 (logistic sigmoid, tanh, relu, leaky relu, ...)\n",
    "- learning rate\n",
    "- hidden layers 갯수\n",
    "- epochs\n",
    "- minibatch size\n",
    "- 각 hidden layer의 neuron 개수\n",
    "\n",
    "**2. 그러나 다음 사항은 변경하지 마세요.**\n",
    "- 가중치 초기화 방법\n",
    "- 랜덤시드\n",
    "- 최적화 방법, 학습 방법\n",
    "\n",
    "**3. layer를 추가하여 2개 이상의 hidden layer를 구성할 수 있게 구현하세요.**\n",
    "\n",
    "**4. 수정가능한 셀은 아래 주석으로 확실하게 하이라이트되어 표시되어 있습니다.**\n",
    "\n",
    "```\n",
    "############################################################\n",
    "# 변경 가능한 셀\n",
    "############################################################\n",
    "```\n",
    "\n",
    "### 점수\n",
    "**Test set 기준**\n",
    "\n",
    "- 정확도 85% 이상 2점\n",
    "- 정확도 86% 이상 4점\n",
    "- 정확도 87% 이상 6점\n",
    "- 정확도 88% 이상 8점\n",
    "\n",
    "**구현**\n",
    "- Layer 수 2개 이상으로 구현: 2점\n",
    "\n",
    "`.ipynb 파일과 함께 .html 파일 (File -> export as -> HTML)도 함께 제출하세요. 하나만 제출할시 감점이 있습니다.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "# Document: https://pytorch.org/docs/stable/nn.functional.html\n",
    "import matplotlib.pyplot as plt\n",
    "# Document: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 부분은 절대 변경하지 마세요.\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 데이터셋은 기존의 MNIST와 비슷하게 10개의 클래스로 이루어진 데이터셋입니다. 또한 흑백의 28x28크기, 60k개의 학습용 이미지와 10k개의 테스트용 이미지로 구성 되어 있는것과 같이 MNIST와 대부분 비슷한 구조로 이뤄져 있습니다. \n",
    "\n",
    "아래는 데이터셋의 샘플 이미지 입니다.\n",
    "\n",
    "![](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)\n",
    "\n",
    "출처: https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 10개의 클래스는 다음과 같습니다.\n",
    "\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 데이터 로딩시 이미지 데이터 전처리를 Transforms를 통해 할 수 있습니다.\n",
    "# ToTensor는 PIL 형태의 이미지나 ndarray 를 PyTorch 가 이해할 수 있는 tensor 자료형으로 바꾸어 주는 역할을 하며\n",
    "# Random Flip, Random Crop 등을 사용하여 Data augmentation을 수행하고 이를 통해 좋은 성능을 얻을 수 있습니다.\n",
    "# 하지만, 이번 실습에서는 사용하지 않습니다.\n",
    "# Document: https://pytorch.org/vision/stable/transforms.html\n",
    "custom_train_transform = transforms.Compose([  \n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터 로딩시 데이터 Transform\n",
    "# Testset의 Trainsform은 Training set 과 다르게 랜덤하게 변경되면 안됩니다.\n",
    "# 이번 실습에서는 사용하지 않습니다.\n",
    "custom_test_transform = transforms.Compose([\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 변경 가능한 셀\n",
    "############################################################\n",
    "\n",
    "# BATCH_SIZE = 60000을 사용하면 Full-Batch 학습\n",
    "# BATCH_SIZE = 1을 사용하면 Online 학습\n",
    "# BATCH_SIZE = N (1 < N < 60000) 을 사용하면 Mini-batch 학습\n",
    "BATCH_SIZE = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(\".\", train=True, download=True, transform=custom_train_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = FashionMNIST(\".\", train=False, download=True, transform=custom_test_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 셀은 데이터셋이 잘 Load 되었는지 확인하는 테스트용 코드입니다.\n",
    "\n",
    "특히, Label data의 경우 One-hot vector encoding 되기 전의 형태의 class label 정보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        print(f'Image data shape: \\t {x.shape}')\n",
    "        print(f'Label data shape: \\t {y.shape}')\n",
    "        print(y)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Multilayer Perceptron Model\n",
    "\n",
    "아래 셀은 MLP모델을 정의하는 부분입니다. 이 과제에서 메인 부분입니다.<br>\n",
    "Hidden layer이 2개가 되도록 변경하세요. 필요에 따라 3개 이상으로 늘려도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 변경 가능한 셀\n",
    "############################################################\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden_1, num_hidden_2, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes # 10 \n",
    "        self.linear_1 = torch.nn.Linear(num_features, num_hidden_1)\n",
    "        \n",
    "        # <your code> to add layer\n",
    "        self.linear_out = torch.nn.Linear(num_hidden_2, num_classes)\n",
    "        \n",
    "        # Multi-class classification 문제를 풀기 위해 Softmax 함수를 사용합니다.\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ### activation 함수 변경 가능\n",
    "        ### 레이어간의 연결 추가, 변경\n",
    "        out = self.linear_1(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        # <your code> to set the layer and the activation function\n",
    "        \n",
    "        logits = self.linear_out(out)\n",
    "        \n",
    "        # Multi-class classification 문제를 풀기 위해 Softmax 함수를 사용합니다.\n",
    "        # 다만, 이후 사용할 F.cross_entropy() 함수 내부에 softmax가 이미 구현되어 있기 때문에\n",
    "        # Loss function 계산 시에는 self.softmax()를 통과하기 전의 logits 값을 이용하게 됩니다.\n",
    "        probas = self.softmax(logits)\n",
    "        return logits, probas\n",
    "\n",
    "# random seed는 무작위 가중치 초기화가 항상 같도록 해줍니다.\n",
    "# 초기화된 가중치에 따라 같은 네트워크도 서로 다른 성능을 낼 수 있어서 \n",
    "# 실제 사용시에는 좋은 성능을 얻기 위해 여러가지 무작위 가중치를 시도해 볼 수 있습니다.\n",
    "# 그러나 이 과제에서는 변경하지 않습니다.\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross entropy loss function 사용 시 주의점**\n",
    "\n",
    "- 모델의 출력인 logits, probas의 차원은 [BATCH_SIZE, num_classes] 형태지만, 정답 Label인 targets 변수의 차원은 [BATCH_SIZE] 입니다. (ex, [1, 3, 2, 4, 9, ..., 3])\n",
    "\n",
    "\n",
    "- 일반적으로 Cross Entropy Loss를 계산하기 위해서는 targets에 one-hot vector encoding을 수행해주어야 하지만, F.cross_entropy() 함수는 이를 내부적으로 수행해줍니다.\n",
    "\n",
    "\n",
    "- 또한, F.cross_entropy() 함수 내부적으로 softmax 함수를 이용하기 때문에, 모델의 출력 중 probas 값이 아닌 logits 값을 이용하여 Loss function을 계산합니다.\n",
    "\n",
    "\n",
    "- 구현 상세는 pytorch documents에서 확인할 수 있습니다. (https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html#torch.nn.functional.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 변경 가능한 셀\n",
    "############################################################\n",
    "\n",
    "### num_hidden_1, num_hidden_2 변경 가능, \n",
    "### 레이어를 더 추가하고 싶다면 이부분을 알맞게 수정하세요.\n",
    "model = MLP(num_features=28*28,\n",
    "            num_hidden_1=10,\n",
    "            num_hidden_2=10,\n",
    "            num_classes=10)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\n",
    "### Optimizer는 가중치를 업데이트하는 방법을 바꾸어 더 빠르게 좋은 성능을 낼 수 있도록합니다.\n",
    "### 이 과제에서는 optimizer를 변경하지 않습니다. \n",
    "### 그러나 Learning Rate(lr)는 변경이 가능합니다.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "NUM_EPOCHS = 2 # 변경 가능\n",
    "############################################################\n",
    "\n",
    "### 아래는 변경 불가능\n",
    "def compute_accuracy_and_loss(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    cross_entropy = 0.\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.view(-1, 28*28).to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        \n",
    "        # Loss 계산 시에는 logits 이용\n",
    "        cross_entropy += F.cross_entropy(logits, targets).item()\n",
    "        \n",
    "        # 추론 시에는 probas 이용\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.cpu().float()/num_examples * 100, cross_entropy/num_examples\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "train_acc_lst, test_acc_lst = [], []\n",
    "train_loss_lst, test_loss_lst = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "    \n",
    "        ### PREPARE MINIBATCH\n",
    "        features = features.view(-1, 28*28).to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 40:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # no need to build the computation graph for backprop when computing accuracy\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        train_acc, train_loss = compute_accuracy_and_loss(model, train_loader, device=DEVICE)\n",
    "        test_acc, test_loss = compute_accuracy_and_loss(model, test_loader, device=DEVICE)\n",
    "        train_acc_lst.append(train_acc)\n",
    "        test_acc_lst.append(test_acc)\n",
    "        train_loss_lst.append(train_loss)\n",
    "        test_loss_lst.append(test_loss)\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Test Acc.: {test_acc:.2f}%')\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Evaluation\n",
    "\n",
    "테스트 데이터와 학습 데이터의 Loss변화를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, NUM_EPOCHS+1), train_loss_lst, label='Training loss')\n",
    "plt.plot(range(1, NUM_EPOCHS+1), test_loss_lst, label='Test loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, NUM_EPOCHS+1), train_acc_lst, label='Training accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS+1), test_acc_lst, label='Test accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    test_acc, test_loss = compute_accuracy_and_loss(model, test_loader, DEVICE)\n",
    "    print(f'Test accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) 학습, 테스트 정확도는 얼마인가요? (위 숫자를 복사하세요.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training:  ???%\n",
    "- Test ???%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) overfitting을 경험했나요? 만약 그랬다면 왜 그랬을지 적어보고, overfitting을 방지하기위한 간단한 방법은 무엇일까요?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[제안하는 방법 적기]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들면, \n",
    "\n",
    "- batch size를 256으로 변경\n",
    "- 두개의 hidden layers의 activation을 relu로 변경\n",
    "- learning rate를 0.2로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) 만약 hidden layer 수가 늘어나면(3개 이상) 얻을 수 있는 장/단점은 무엇일까요?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) 구현하면서 수정한 부분에 대해 작성하여 수정한 이유 및 성능향상이 생긴 이유에 대해 답해보세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
