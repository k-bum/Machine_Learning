{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SWCON253] Machine Learning\n",
    "Teaching Assistant: Yeongwoong Kim (duddnd7575@khu.ac.kr)\n",
    "\n",
    "Professor: Hui Yong Kim (hykim.v@khu.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P1:  Pure Python만을 이용하여 Perceptron 구현 (10점)\n",
    "\n",
    "### 학습목표\n",
    "- Perceptron Python class를 직접 구현하면서 NN의 작동방법을 이해한다.\n",
    "- 머신러닝 모델의 데이터 준비, 개발, 학습, 검증, 시각화 과정을 이해하고 설명 할 수 있다.\n",
    "\n",
    "### 실습내용\n",
    "Frank Rosenblatt의 classic perceptron binary classication(0 또는 1을 구분하는)을 구현합니다. <br>\n",
    "여러분은 \"Pure\" 혹은 \"vanilla\" Python 함수만을 사용하여 구현해야합니다. 그러므로 시각화를 위한 matplotlib 이외의 패키지는 사용하지마세요.\n",
    "\n",
    "실습은 다음 순서로 진행됩니다. 학생분들께서는 **<구현>**과 **<작성>**에 해당하는 부분을 수행해주시면 됩니다.\n",
    "\n",
    "- S1. Perceptron 구현 및 분석\n",
    "    - 1) 실습에서 사용되는 패키지 import\n",
    "    - 2) 주어진 데이터셋 loading\n",
    "    - 3) Perceptron Model 구현 **<구현>**\n",
    "    - 4) Perceptron Model 학습\n",
    "    - 5) Perceptron Model 검증\n",
    "    - 6) Decision Boundary 시각화\n",
    "\n",
    "<br>\n",
    "\n",
    "- S2. Discussion **<작성>**\n",
    "\n",
    "### 점수\n",
    "- Perceptron model 구현: 각 함수별로 2점\n",
    "\n",
    "\n",
    "### 제출방법\n",
    "- .ipynb 파일과 함께 .html 파일 (File -> export as -> HTML)도 함께 제출하세요. 하나만 제출할시 감점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1.  Perceptron 구현 및 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1) Imports\n",
    "**수정하지 마세요.** HW1에서는 \"pure\" python으로만 코드를 작성합니다. `matplotlib`이외의 패키지는 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2) Loading the Dataset\n",
    "**수정하지 마세요.** \n",
    "\n",
    "코드를 실행시켜 실습코드와 같이 첨부된 dataset.csv파일을 로드합니다.\n",
    "\n",
    "두 개의 class(0, 1)를 갖는 2차원 데이터이며, class0은 -1의 값을 가지고 class1은 1의 값을 가집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일을 읽기\n",
    "X, y = [], []\n",
    "\n",
    "with open('./dataset.csv', 'r') as f:\n",
    "    next(f)\n",
    "    classes = [-1, 1]\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            values = line.split(',')\n",
    "        else:\n",
    "            continue\n",
    "        X.append([float(i) for i in values[:2]])\n",
    "#         y.append(int(values[-1])\n",
    "        y.append(classes[int(values[-1])])\n",
    "        \n",
    "print(len(X), len(y))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Split & Visualization\n",
    "\n",
    "**수정하지 마세요.** \n",
    "\n",
    "Load 된 데이터셋을 모델 학습과 검증을 위해 Trainset과 Testset으로 랜덤 샘플링하여 나누고 데이터셋이 어떤 분포로 생겼는지 시각화하여 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# 랜덤시드 설정\n",
    "random.seed(123)\n",
    "\n",
    "# 데이터 랜덤 셔플\n",
    "idx = list(range(len(X)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "# 앞 80개 까지는 학습용으로 뒤 20개는 테스트용으로 split\n",
    "X_train = [X[i] for i in idx[:80]]\n",
    "y_train = [y[i] for i in idx[:80]]\n",
    "X_test = [X[i] for i in idx[80:]]\n",
    "y_test = [y[i] for i in idx[80:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 별로 데이터를 시각화 하여 분포를 살펴보기\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_train) if y_train[idx] == -1], \n",
    "            [i[1] for idx, i in enumerate(X_train) if y_train[idx] == -1],\n",
    "            label='class 0', marker='o')\n",
    "\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_train) if y_train[idx] == 1], \n",
    "            [i[1] for idx, i in enumerate(X_train) if y_train[idx] == 1],\n",
    "            label='class 1', marker='s')\n",
    "\n",
    "plt.title('Training set')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('feature 2')\n",
    "plt.xlim([0.0, 7])\n",
    "plt.ylim([-0.8, 0.8])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3) Perceptron model 구현\n",
    "이 부분에서는 직접 `Perceptron model`을 구현해 봅니다.\n",
    "\n",
    "Perceptron model은 생성자, forward, backward, train, evaluation 다섯개 함수로 이루어져 있습니다.\n",
    "- `__init__` 생성자에서는 Perceptron의 weights와 bias를 초기화합니다.\n",
    "- `forward`에서는 input을 Perceptron의 가중치를 이용해서 예측을 수행합니다.\n",
    "- `backward`에서는 Perceptron의 가중치를 학습하기 위해 에러를 계산합니다.\n",
    "- `train`에서는 Perceptron을 학습하는 과정으로 `forward`와 `backward`를 차례로 반복하여 Perceptron의 가중치를 업데이트 합니다.\n",
    "- `evaluation`에서는 들어온 input data를 학습된 가중치를 이용하여 예측하고 결과를 반환합니다. **(주의: Accuracy 계산)**\n",
    "\n",
    "아래 `# <your code>` 부분을 채워 넣어서 Perceptron class를 직접 작성하여 구현하세요.\n",
    "\n",
    "**세부 구현 사항:**\n",
    "- weights는 랜덤으로 초기화, bias는 0으로 초기화한다.\n",
    "- activation function은 입력값을 기준으로 `0 초과는 1, 0 이하는 -1`을 출력하게 한다.\n",
    "- Cost Function은 MSE 또는 Cross-Entropy가 아닌 $J(w) = -y(w^Tx)$를 사용한다. , $x\\in Y$는 **틀린 샘플의 집합** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron\n",
    "![Perceptron](https://www.researchgate.net/profile/Daniel-Alvarez-34/publication/315788933/figure/fig3/AS:479799241121795@1491404461957/Scheme-of-a-perceptron-A-nonlinear-activation-function-BULLET-is-applied-to-the.png)\n",
    "출처: https://www.researchgate.net/figure/Scheme-of-a-perceptron-A-nonlinear-activation-function-BULLET-is-applied-to-the_fig3_315788933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self, num_features):\n",
    "        self.weights = # <your code> initialization\n",
    "        self.bias = # <your code> initialization\n",
    "        self.lr = 0.01\n",
    "        \n",
    "    def forward(self, x):\n",
    "        linear = # <your code> compute weighted sum\n",
    "        prediction = # <your code> apply activation \n",
    "        return prediction\n",
    "        \n",
    "    def backward(self, x, y):\n",
    "        error = # <your code> to compute the prediction error\n",
    "        return error\n",
    "        \n",
    "    def train(self, x, y, epochs):\n",
    "        # epochs 만큼 학습\n",
    "        for e in range(epochs):\n",
    "            # Each data point (Stochastic learning)\n",
    "            for i in range(len(y)):\n",
    "                x_, y_ = x[i], y[i]\n",
    "            \n",
    "                if y_ != self.forward(x_):\n",
    "                    # <your code> to update the weights and bias\n",
    "                    \n",
    "    def evaluate(self, x, y):\n",
    "        # <your code> to compute the prediction accuracy       \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4) Perceptron 학습\n",
    "\n",
    "작성한 Perceptron을 Trainset을 이용해 5 epoch 학습하고 학습된 weight, bias를 print합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppn = Perceptron(num_features=2)  # 위에서 구현한 Perceptron 모델 정의\n",
    "ppn.train(X_train, y_train, 10)    # 10 epoch 학습\n",
    "\n",
    "# 학습된 모델의 weight, bias 출력\n",
    "print(ppn.weights)\n",
    "print(ppn.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-5) 모델 평가\n",
    "Training set과 Test set각각에서 모델의 accuracy를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset에서 성능 평가\n",
    "train_acc = ppn.evaluate(X_train, y_train)\n",
    "print('Train set accuracy: %.2f%%' % (train_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset에서 성능 평가\n",
    "test_acc = ppn.evaluate(X_test, y_test)\n",
    "print('Test set accuracy: %.2f%%' % (test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-6) Decision Boundary\n",
    "train 데이터셋과 test 데이터셋 각각을 이용하여 2개의 scatter plot을 그리고 그 위에 학습된 가중치를 이용하여 결정경계를 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train 데이터셋에서 Decision Boundary 시각화\n",
    "# 그래프로 표현\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_train) if y_train[idx] == -1], \n",
    "            [i[1] for idx, i in enumerate(X_train) if y_train[idx] == -1],\n",
    "            label='class 0', marker='o')\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_train) if y_train[idx] == 1], \n",
    "            [i[1] for idx, i in enumerate(X_train) if y_train[idx] == 1],\n",
    "            label='class 1', marker='s')\n",
    "# Perscptron의 Weight와 Bias를 그래프로 표현\n",
    "plt.plot([0, 7], [-ppn.bias/ppn.weights[1], -(7*ppn.weights[0] + ppn.bias)/ppn.weights[1]])\n",
    "\n",
    "# 그래프로 표현\n",
    "plt.title('Training set')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('feature 2')\n",
    "plt.xlim([0.0, 7])\n",
    "plt.ylim([-0.8, 0.8])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "### Test 데이터셋에서 Decision Boundary 시각화\n",
    "# 그래프로 표현\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_test) if y_test[idx] == -1], \n",
    "            [i[1] for idx, i in enumerate(X_test) if y_test[idx] == -1],\n",
    "            label='class 0', marker='o')\n",
    "\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_test) if y_test[idx] == 1], \n",
    "            [i[1] for idx, i in enumerate(X_test) if y_test[idx] == 1],\n",
    "            label='class 1', marker='s')\n",
    "# Perscptron의 Weight와 Bias를 그래프로 표현\n",
    "plt.plot([0, 7], [-ppn.bias/ppn.weights[1], -(7*ppn.weights[0] + ppn.bias)/ppn.weights[1]])\n",
    "\n",
    "# 그래프로 표현\n",
    "plt.title('Test set')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('feature 2')\n",
    "plt.xlim([0.0, 7])\n",
    "plt.ylim([-0.8, 0.8])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2. Discussion\n",
    "\n",
    "**1) 예시에서 사용된 activation 함수 이외의 어떤 함수가 있는지 찾아보고 설명해보세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Perceptron 하나로 풀 수 없는 문제는 어떤것이 있는지 왜 그런지 설명해보세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
