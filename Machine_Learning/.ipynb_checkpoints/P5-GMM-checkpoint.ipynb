{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SWCON253] Machine Learning\n",
    "Teaching Assistant: Yeongwoong Kim (duddnd7575@khu.ac.kr)\n",
    "\n",
    "Professor: Hui Yong Kim (hykim.v@khu.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5.A:  GMM을 이용한 밀도추정 (10점)\n",
    "\n",
    "### 학습목표\n",
    "- GMM 모델을 이용하여 밀도추정을 할 수 있다.\n",
    "- Scikit-Learn을 이용하여 모델 학습을 구현할 수 있다.\n",
    "\n",
    "### 실습내용\n",
    "Scikit-Learn의 GMM을 이용하여 군집화를 학습해 봅니다.  \n",
    "Scikit-Learn에서 Gaussian Mixture 클래스 사용법을 제공하니 아래 링크를 참고하세요.  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "\n",
    "실습은 다음 순서로 진행됩니다.\n",
    "- Imports\n",
    "- 1) 데이터 생성\n",
    "- 2) GMM 모델 구현, 학습, Centroids, Density Contour 시각화 **<직접 구현>**\n",
    "- 3) GMM에서의 Covariance matrix 분석과  type (제약 조건)에 따른 클러스터 모양 시각화\n",
    "- 4) Discussion **<작성>**\n",
    "\n",
    "**이번 실습에서 여러분은 `2)` 부분의 코드와 `3)`을 직접 작성합니다.**\n",
    "\n",
    "### 점수\n",
    "- 코드 작성: 8점, `#<your code>` 한 부분 마다 2점.\n",
    "- Discussion 작성: 2점\n",
    "\n",
    "`.ipynb 파일과 함께 .html 파일 (File -> export as -> HTML)도 함께 제출하세요. 하나만 제출할시 감점이 있습니다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib.colors import LogNorm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 생성\n",
    "랜덤하게 데이터를 생성하며 Trainset과 Testset으로 랜덤 샘플링하여 나누고 데이터셋이 어떤 분포로 생겼는지 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "X1, y1 = make_blobs(n_samples=1000, centers=((5, -4), (0, 0)), random_state=42)\n",
    "X1 = X1.dot(np.array([[0.37, 0.95], [0.73, 0.6]]))\n",
    "X2, y2 = make_blobs(n_samples=500, centers=1, random_state=42)\n",
    "X = np.r_[X1, X2]\n",
    "X[:, [0, 1]] = X[:, [1, 0]]\n",
    "\n",
    "#데이터를 훈련 데이터와 테스트 데이터로 분류\n",
    "# X_test는 P5.B에서 사용\n",
    "X_train, X_test = train_test_split(X, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axes().set_aspect('equal')\n",
    "\n",
    "plt.plot(X_train[:, 0], X_train[:, 1], '.', markersize=3)\n",
    "plt.title('Random Blobs for Training')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.plot(X_test[:, 0], X_test[:, 1], '.', markersize=3, color='r')\n",
    "plt.title('Random Blobs for Test')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) GMM 모델 구현, 학습, 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Scikit-Learn의 `GaussianMixture` 클래스를 이용하여 GMM을 생성하고 `fit` 함수를 이용하여 학습해 봅니다.  \n",
    " - GaussianMixture의 `n_components`를 이용하면 군집의 갯수를 정할 수 있습니다. 이번 실습에서는 3개로 합니다.  \n",
    " - 또한, GMM을 생성할 때 하이퍼파라메터인 `n_init`을 10으로 설정해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = # <your code> Gaussian Mixture 생성\n",
    "# <your code> 훈련 데이터(X_train)를 이용하여 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 학습된 GMM 모델을 이용하여 다음 정보들을 획득할 수 있습니다.\n",
    "\n",
    "**1. Centriods (군집 중심)**\n",
    " \n",
    "**2. Density Contour (밀도 등고선)**\n",
    " \n",
    "이어지는 셀들에서 이러한 정보들을 시각화합니다.\n",
    "\n",
    "이때, GaussianMixture 클래스의 함수와 attributes를 이용합니다. \n",
    "\n",
    "- `GaussianMixture.means_`: returns Centroids\n",
    "- `GaussianMixture.score_samples(array)`: returns log-likelihoods (for each sample)\n",
    "\n",
    "(주의: 위의 셀에서 학습이 끝난 gmm 객체를 이후 모든 셀에서 이용합니다.)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Centroids (군집 중심) 시각화**\n",
    "- GMM 클래스로부터 군집 중심을 반환하여 시각화합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_centroids(gmm):\n",
    "    # Centroids 시각화\n",
    "    centroids = # <your code> to use the mean of each components to get the centroids\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], marker='o', s=200, linewidths=1, color='c', zorder=10) \n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=150, linewidths=1, color='yellow', zorder=11) \n",
    "\n",
    "    \n",
    "# Figure 생성\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axes().set_aspect('equal')\n",
    "    \n",
    "# Centroids\n",
    "visualization_centroids(gmm)\n",
    "\n",
    "# 축 이름 설정\n",
    "plt.xlabel(\"$f_1$\")\n",
    "plt.ylabel(\"$f_2$\", rotation=0)\n",
    "\n",
    "# X_train 데이터 시각화\n",
    "plt.plot(X_train[:, 0], X_train[:, 1], '.', markersize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Density Contour (밀도 등고선) 시각화**\n",
    "- 밀도 등고선을 시각화하기 위해 2차원 평면공간에 촘촘한 격자점을 생성합니다.\n",
    "- GMM 클래스로부터 격자점들의 위치에서의 **log-likelihoods** 를 반환하여 확률 밀도로써 사용합니다.\n",
    "- matplotlib에서 지원하는 contourf 함수를 이용하여 밀도 등고선을 시각화합니다.\n",
    "\n",
    "**주의**: GMM 클래스가 반환하는 log-likelihoods에서 likelihoods는 GMM이 가지고 있는 가우시안 분포들의 각각의 likelihoods가 아닌, 최종 가충 합으로 계산된 likelihoods 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_contour(gmm):\n",
    "    # 2차원 평면 공간 격자점 Array 생성\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    x, y = np.meshgrid(np.linspace(mins[0], maxs[0], num=1000),np.linspace(mins[1], maxs[1], num=1000))\n",
    "    plane = np.c_[x.ravel(), y.ravel()]\n",
    "\n",
    "    # densities (log-likelihoods) \n",
    "    densities = # <your code> to compute the likelihood of each sample\n",
    "\n",
    "    densities = np.abs(densities.reshape(x.shape))\n",
    "    cntr = plt.contourf(x, y, densities, levels=10, alpha=0.3, cmap='gist_rainbow')\n",
    "    plt.contour(x, y, densities, levels=10, linewidths=1, colors='k')\n",
    "\n",
    "# Figure 생성\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axes().set_aspect('equal')\n",
    "\n",
    "# contour \n",
    "visualization_contour(gmm)\n",
    "\n",
    "# 축 이름 설정\n",
    "plt.xlabel(\"$f_1$\")\n",
    "plt.ylabel(\"$f_2$\", rotation=0)\n",
    "\n",
    "# X_train 데이터 시각화\n",
    "plt.plot(X_train[:, 0], X_train[:, 1], '.', markersize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) GMM에서의 Covariance matrix 분석과  type (제약 조건)에 따른 클러스터 모양 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM을 충분히 학습시키고 나면, GMM에 포함된 각 가우시안 분포에 해당하는 Covariance matrix를 확인할 수 있습니다.\n",
    "\n",
    "예를 들어, 현재 학습된 GMM 모델의 Covariance matrix는 다음과 같습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariances = gmm.covariances_\n",
    "print('Covariance matrix 1\\n', covariances[0],\n",
    "     '\\n\\nCovariance matrix 2\\n', covariances[1],\n",
    "      '\\n\\nCovariance matrix 3\\n', covariances[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 셀에서 학습한 GMM의 Covariance는 아무런 제약 조건이 없지만(default), 제약 조건을 추가하여 Covariancce를 학습할 수 있습니다.\n",
    "\n",
    "이어지는 셀에서는 GMM 모델을 생성할 때 Covariance type를 다른 type ('tied', 'diag')로 바꾸어 학습하여 클러스터의 모양이 어떻게 변하는지 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Covariance type: Tied**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_tied = GaussianMixture(n_components=3, n_init=10, covariance_type='tied')\n",
    "gmm_tied.fit(X_train)\n",
    "\n",
    "# Figure 생성\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axes().set_aspect('equal')\n",
    "\n",
    "# contour \n",
    "visualization_contour(gmm_tied)\n",
    "\n",
    "# 축 이름 설정\n",
    "plt.xlabel(\"$f_1$\")\n",
    "plt.ylabel(\"$f_2$\", rotation=0)\n",
    "\n",
    "# X_train 데이터 시각화\n",
    "plt.plot(X_train[:, 0], X_train[:, 1], '.', markersize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Covariance type: diag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_diag = GaussianMixture(n_components=3, n_init=10, covariance_type='diag')\n",
    "gmm_diag.fit(X_train) \n",
    "\n",
    "# Figure 생성\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axes().set_aspect('equal')\n",
    "\n",
    "# contour \n",
    "visualization_contour(gmm_diag)\n",
    "\n",
    "# 축 이름 설정\n",
    "plt.xlabel(\"$f_1$\")\n",
    "plt.ylabel(\"$f_2$\", rotation=0)\n",
    "\n",
    "# X_train 데이터 시각화\n",
    "plt.plot(X_train[:, 0], X_train[:, 1], '.', markersize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Discussion (각 0.5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) 모수적 밀도추정과 비모수적 밀도추정을 비교하여 설명하세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) EM 알고리즘을 이용한 GMM 밀도추정 방법에 대해  설명하세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) K-means를 이용한 군집화와 GMM을 이용한 밀도추정 기반의 군집화의 차이에 대해 설명하세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) 앞서 학습된 GMM의 Covariance matrix들을 출력해보았습니다. 출력된 각 Covariance matrix (cluster1~3)의 값과 시각화한 밀도 등고선의 모양을 연결지어 설명해보세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5.B: 학습한 GMM (P5.A의 결과)를 이용한 새로운 샘플(Test) 분류 (3점)\n",
    "### 학습목표\n",
    "- 학습한 GMM 모델을 이용하여 새로운 데이터를 분류할 수 있다.\n",
    "\n",
    "### 실습내용\n",
    "Scikit-Learn에서 Gaussian Mixture 클래스 사용법을 제공하니 아래 링크를 참고하세요.  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "\n",
    "실습은 다음 순서로 진행됩니다.\n",
    "- 1) 학습된 GMM을 이용하여 클래스 분류 **<직접 구현>** \n",
    "- 2) 결정 경계 시각화\n",
    "\n",
    "**이번 실습에서 여러분은 `1)` 부분의 코드를 직접 작성합니다.**\n",
    "\n",
    "앞으로 대부분의 실습도 위와 같은 순서로 진행됩니다. 이번 실습을 통해 각 부분의 코드를 이해하고 다음 실습에 참고하도록합니다.\n",
    "\n",
    "### 점수\n",
    "- 코드 작성: 3점, `#<your code>`\n",
    "\n",
    "`.ipynb 파일과 함께 .html 파일 (File -> export as -> HTML)도 함께 제출하세요. 하나만 제출할시 감점이 있습니다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 학습된 GMM을 이용하여 클래스 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 새로운 샘플 (test dataset)이 어느 군집에 속해있는지 분류합니다.\n",
    "- GaussianMixture.predict(array) 함수를 이용합니다.\n",
    "\n",
    "훈련 데이터로 학습한 GMM을 새로운 샘플들 (Test dataset)에 대한 분류를 진행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(gmm):\n",
    "    y = # <your code> to get the prediction\n",
    "\n",
    "    # 테스트 데이터에 대해 Class 분류\n",
    "    plt.scatter([i[0] for idx, i in enumerate(X_test) if y[idx] == 0], \n",
    "                [i[1] for idx, i in enumerate(X_test) if y[idx] == 0],\n",
    "                label='cluster(class) 0', marker='o', color='coral', alpha=0.5, s=100)\n",
    "    plt.scatter([i[0] for idx, i in enumerate(X_test) if y[idx] == 1], \n",
    "                [i[1] for idx, i in enumerate(X_test) if y[idx] == 1],\n",
    "                label='cluster(class) 1', marker='o', color='dodgerblue', alpha=0.5, s=100)\n",
    "    plt.scatter([i[0] for idx, i in enumerate(X_test) if y[idx] == 2], \n",
    "                [i[1] for idx, i in enumerate(X_test) if y[idx] == 2],\n",
    "                label='cluster(class) 2', marker='o', color='green', alpha=0.3, s=100)\n",
    "\n",
    "\n",
    "# Figure 생성\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axes().set_aspect('equal')\n",
    "\n",
    "# 테스트 데이터셋의 샘플 분류\n",
    "classification(gmm)\n",
    "plt.plot(X_test[:, 0], X_test[:, 1], '.r', markersize=4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 결정 경계 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_decision_boundary(gmm):\n",
    "    # 2차원 평면 공간 격자점 Array 생성\n",
    "    mins = X.min(axis=0) - 1\n",
    "    maxs = X.max(axis=0) + 1\n",
    "    x, y = np.meshgrid(np.linspace(mins[0], maxs[0], num=1000),np.linspace(mins[1], maxs[1], num=1000))\n",
    "    plane = np.c_[x.ravel(), y.ravel()]\n",
    "\n",
    "    # 결정 경계 시각화\n",
    "    Z = gmm.predict(plane)\n",
    "    Z = Z.reshape(x.shape)\n",
    "    plt.contour(x, y, Z, linewidths=1, cmap='winter', linestyles='dashed')\n",
    "\n",
    "# Figure 생성\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axes().set_aspect('equal')\n",
    "\n",
    "# 위에서 진행한 분류 및 시각화\n",
    "classification(gmm)\n",
    "plt.plot(X_test[:, 0], X_test[:, 1], '.r', markersize=4)\n",
    "plt.legend()\n",
    "\n",
    "# 결정 경계 시각화\n",
    "visualization_decision_boundary(gmm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5.C: 학습한 GMM (P5.A의 결과)를 이용한 이상치 탐지 (2점)\n",
    "### 학습목표\n",
    "- 학습한 GMM 모델을 이용하여 이상치 탐지를 할 수 있다.\n",
    "\n",
    "### 실습내용\n",
    "Scikit-Learn에서 Gaussian Mixture 클래스 사용법을 제공하니 아래 링크를 참고하세요.  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "\n",
    "실습은 다음 순서로 진행됩니다.\n",
    "- 1) 밀도 임계값 지정 **<직접 구현>**\n",
    "- 2) 이상치 시각화 \n",
    "\n",
    "**이번 실습에서 여러분은 `1)` 부분의 코드를 직접 작성합니다.**\n",
    "\n",
    "앞으로 대부분의 실습도 위와 같은 순서로 진행됩니다. 이번 실습을 통해 각 부분의 코드를 이해하고 다음 실습에 참고하도록합니다.\n",
    "\n",
    "\n",
    "### 점수\n",
    "- 모델 작성: 2점, `#<your code>` 한 부분 마다 1점.\n",
    "\n",
    "`.ipynb 파일과 함께 .html 파일 (File -> export as -> HTML)도 함께 제출하세요. 하나만 제출할시 감점이 있습니다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier\n",
    "![Outlier](https://miro.medium.com/max/1400/1*w5HzgB5ekxQ6Nwmx5ggn8Q.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM을 이상치 탐지에 사용할 수 있습니다. 밀도가 낮은 지역에 있는 샘플을 이상치로 생각할 수 있습니다. 예를 들어 결함 제품의 비율이 4%라고 하면 밀도 임곗값을 이 값으로 지정하여 임계 밀도보다 낮은 지역에 있는 샘플을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 밀도 임계값 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **학습 데이터**의 이상치 탐지를 위해 각 샘플에 대한 확률 밀도 **(log-likelihoods)** 를 구합니다. (**GaussianMixture.score_samples()** 함수 이용)\n",
    "- **np.percentile(array, n)** 함수를 이용하여 입력 array의 성분 값들 중 n percentile (n% 이하의 값에 대한 경곗값)를 반환합니다.\n",
    "- 본 실습에서는 n=4 를 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = # <your code> to get the densities of the trained data\n",
    "\n",
    "# 밀도 임계값 지정\n",
    "threshold = # <your code> to get 4-th percentile value\n",
    "\n",
    "# threshold 보다 작은 확률 밀도를 가진 샘플을 이상치로 탐지\n",
    "anomalies = X_train[densities < threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 이상치 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_likelihood(i):\n",
    "    posX, posY = anomalies[i][0]-0.5, anomalies[i][1]+0.1\n",
    "    likelihood = round(np.exp(gmm.score_samples(anomalies[i].reshape(1, -1)))[0].item(), 4)\n",
    "    plt.text(posX, posY, f'{likelihood}', fontdict={'size': 12}, color='red')\n",
    "\n",
    "\n",
    "# Figure 생성\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axes().set_aspect('equal')\n",
    "\n",
    "\n",
    "visualization_centroids(gmm)\n",
    "visualization_contour(gmm)\n",
    "\n",
    "# visualization likelihoods (10 samples)\n",
    "for i in range(10):\n",
    "    visualization_likelihood(i)\n",
    "\n",
    "plt.plot(X_train[:, 0], X_train[:, 1], '.', markersize=4)\n",
    "plt.scatter(anomalies[:, 0], anomalies[:, 1], color='r', marker='*')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
