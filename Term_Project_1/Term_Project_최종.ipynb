{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef5af55",
   "metadata": {},
   "source": [
    "#### 필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6e3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68f99f",
   "metadata": {},
   "source": [
    "#### 데이터 전처리\n",
    "1. data의 column 이름을 적절하게 변경\n",
    "2. 결측치 값의 존재유무를 확인해 존재한다면 제거\n",
    "3. 연령 별로 정렬된 데이터를 학습을 위해 랜덤하게 shuffle\n",
    "4. 연령 별로 grouping된 데이터를 연령대 데이터로 변경(ex. 연령(그룹)이 1인 경우 20대로 변경)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a63b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data를 csv파일 형태로 읽어와 data에 저장\n",
    "data = pd.read_csv(\"국가건강검진_혈압혈당데이터_원본.csv\", encoding = 'utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d28685",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285218e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data의 column 이름을 적절하게 변경\n",
    "data.rename(columns = {\"SEX\" : \"성별\", \"BTH_G\" : \"연령(그룹)\", \"SBP\" : \"수축기혈압\",\n",
    "                      \"DBP\" : \"이완기혈압\", \"FBS\" : \"공복기혈당\", \"DIS\" : \"고혈압/당뇨병 진료여부\",\n",
    "                      \"BMI\" : \"체질량지수\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4321a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "#### 성별 (1 : 남자, 2: 여자)\n",
    "#### 고혈압/당뇨병 진료여부 (1 : 고혈압/당뇨병 진료내역 있음, 2 : 고혈압 진료내역 있음, 3 : 당뇨 진료내역 있음, 4 : 진료내역 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da44be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"연령대\"] = 0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa185cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# na값 확인\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shuffle\n",
    "data = data.sample(frac=1).reset_index(drop = True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e52ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data의 연령을 읽어와 20~70대의 연령대 형태로 저장\n",
    "for i in range(len(data)) :\n",
    "    if (data[\"연령(그룹)\"][i] in [1, 2, 3, 4]) :\n",
    "        data[\"연령대\"][i] = 20\n",
    "    elif (data[\"연령(그룹)\"][i] in [5, 6, 7, 8, 9]) :\n",
    "        data[\"연령대\"][i] = 30\n",
    "    elif (data[\"연령(그룹)\"][i] in [10, 11, 12, 13, 14]) :\n",
    "        data[\"연령대\"][i] = 40\n",
    "    elif (data[\"연령(그룹)\"][i] in [15, 16, 17, 18, 19]) :\n",
    "        data[\"연령대\"][i] = 50\n",
    "    elif (data[\"연령(그룹)\"][i] in [20, 21, 22, 23, 24]) :\n",
    "        data[\"연령대\"][i] = 60\n",
    "    else :\n",
    "        data[\"연령대\"][i] = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c77801",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[\"연령(그룹)\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d29f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 데이터를 저장\n",
    "data.to_csv(\"혈압혈당_데이터_가공.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ffd974",
   "metadata": {},
   "source": [
    "#### 전처리된 데이터를 바탕으로 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00f7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 데이터를 csv형태로 읽어와서 data에 저장\n",
    "data = pd.read_csv(\"혈압혈당_데이터_가공.csv\", encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7473a9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성별</th>\n",
       "      <th>수축기혈압</th>\n",
       "      <th>이완기혈압</th>\n",
       "      <th>공복기혈당</th>\n",
       "      <th>고혈압/당뇨병 진료여부</th>\n",
       "      <th>체질량지수</th>\n",
       "      <th>연령대</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>75</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>86</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>24.4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>75</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>66</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>22.2</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>27.9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        성별  수축기혈압  이완기혈압  공복기혈당  고혈압/당뇨병 진료여부  체질량지수  연령대\n",
       "0        2    120     90     79             2   21.0   40\n",
       "1        2    119     75    108             1   24.0   60\n",
       "2        1    122     86    102             4   24.4   40\n",
       "3        1    120     75     89             4   24.8   30\n",
       "4        2    101     66     79             4   22.9   30\n",
       "...     ..    ...    ...    ...           ...    ...  ...\n",
       "999995   2    120     70     92             2   22.2   70\n",
       "999996   1    130     70     76             3   21.0   60\n",
       "999997   1    121     66    103             4   24.9   30\n",
       "999998   1    137     72     82             4   27.9   50\n",
       "999999   2    138     89     92             4   20.3   40\n",
       "\n",
       "[1000000 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2710c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성별</th>\n",
       "      <th>수축기혈압</th>\n",
       "      <th>이완기혈압</th>\n",
       "      <th>공복기혈당</th>\n",
       "      <th>체질량지수</th>\n",
       "      <th>연령대</th>\n",
       "      <th>고혈압/당뇨병 진료여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>79</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>75</td>\n",
       "      <td>108</td>\n",
       "      <td>24.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>86</td>\n",
       "      <td>102</td>\n",
       "      <td>24.4</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>75</td>\n",
       "      <td>89</td>\n",
       "      <td>24.8</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>66</td>\n",
       "      <td>79</td>\n",
       "      <td>22.9</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>92</td>\n",
       "      <td>22.2</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>21.0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>24.9</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>27.9</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>20.3</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        성별  수축기혈압  이완기혈압  공복기혈당  체질량지수  연령대  고혈압/당뇨병 진료여부\n",
       "0        2    120     90     79   21.0   40             2\n",
       "1        2    119     75    108   24.0   60             1\n",
       "2        1    122     86    102   24.4   40             4\n",
       "3        1    120     75     89   24.8   30             4\n",
       "4        2    101     66     79   22.9   30             4\n",
       "...     ..    ...    ...    ...    ...  ...           ...\n",
       "999995   2    120     70     92   22.2   70             2\n",
       "999996   1    130     70     76   21.0   60             3\n",
       "999997   1    121     66    103   24.9   30             4\n",
       "999998   1    137     72     82   27.9   50             4\n",
       "999999   2    138     89     92   20.3   40             4\n",
       "\n",
       "[1000000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data의 열 순서 변경\n",
    "data = data[['성별', '수축기혈압', '이완기혈압', '공복기혈당', '체질량지수', '연령대', '고혈압/당뇨병 진료여부']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00579298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성별</th>\n",
       "      <th>수축기혈압</th>\n",
       "      <th>이완기혈압</th>\n",
       "      <th>공복기혈당</th>\n",
       "      <th>체질량지수</th>\n",
       "      <th>연령대</th>\n",
       "      <th>고혈압/당뇨병 진료여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.489773</td>\n",
       "      <td>121.871763</td>\n",
       "      <td>75.787874</td>\n",
       "      <td>98.864428</td>\n",
       "      <td>23.804029</td>\n",
       "      <td>43.919420</td>\n",
       "      <td>3.471040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499896</td>\n",
       "      <td>14.561706</td>\n",
       "      <td>9.793411</td>\n",
       "      <td>22.981300</td>\n",
       "      <td>3.297287</td>\n",
       "      <td>14.356802</td>\n",
       "      <td>0.946151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>40.300000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   성별           수축기혈압           이완기혈압           공복기혈당  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         1.489773      121.871763       75.787874       98.864428   \n",
       "std          0.499896       14.561706        9.793411       22.981300   \n",
       "min          1.000000       82.000000       50.000000       60.000000   \n",
       "25%          1.000000      110.000000       70.000000       87.000000   \n",
       "50%          1.000000      120.000000       76.000000       94.000000   \n",
       "75%          2.000000      130.000000       80.000000      104.000000   \n",
       "max          2.000000      190.000000      120.000000      358.000000   \n",
       "\n",
       "                체질량지수             연령대    고혈압/당뇨병 진료여부  \n",
       "count  1000000.000000  1000000.000000  1000000.000000  \n",
       "mean        23.804029       43.919420        3.471040  \n",
       "std          3.297287       14.356802        0.946151  \n",
       "min         14.800000       20.000000        1.000000  \n",
       "25%         21.500000       30.000000        3.000000  \n",
       "50%         23.600000       40.000000        4.000000  \n",
       "75%         25.800000       50.000000        4.000000  \n",
       "max         40.300000       70.000000        4.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터의 통계 확인\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14418906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "고혈압/당뇨병 진료여부\n",
       "1    0.053398\n",
       "2    0.162826\n",
       "3    0.043114\n",
       "4    0.740662\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 고혈압/당뇨병 진료여부 별 비율\n",
    "grouped = data.groupby(data[\"고혈압/당뇨병 진료여부\"]).size()/len(data)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67555294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "120\n",
      "358\n",
      "40.3\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(max(data[\"수축기혈압\"]))\n",
    "print(max(data[\"이완기혈압\"]))\n",
    "print(max(data[\"공복기혈당\"]))\n",
    "print(max(data[\"체질량지수\"]))\n",
    "print(max(data[\"연령대\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31264d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-1 normalization(학습 속도를 높이기 위함) --> 각 데이터를 최댓값으로 나눠줌\n",
    "data[\"수축기혈압\"] /= 190\n",
    "data[\"이완기혈압\"] /= 120\n",
    "data[\"공복기혈당\"] /= 358\n",
    "data[\"체질량지수\"] /= 40.3\n",
    "data[\"연령대\"] /= 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8644acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "dclass = {1:[1,0,0,0], 2:[0,1,0,0], 3:[0,0,1,0], 4:[0,0,0,1]}\n",
    "\n",
    "# 1000000 * 4 다차원 벡터 생성\n",
    "Y = np.empty((1000000,4)) \n",
    "\n",
    "# 고혈압/당뇨병 진료여부가 1이면 [1,0,0,0]과 같이 할당\n",
    "for i, v in enumerate(data[\"고혈압/당뇨병 진료여부\"]):\n",
    "    Y[i] = dclass[v] \n",
    "X = data.iloc[:, 0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00d086ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset(80만 개)\n",
    "X_train, Y_train = X[0:800000], Y[0:800000]\n",
    "\n",
    "# test dataset(20만 개)\n",
    "X_test, Y_test = X[800000:], Y[800000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78fba839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 6)\n",
      "(800000, 4)\n",
      "[0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 6개의 특징(feature)를 가진 800000개 데이터\n",
    "print(X_train.shape)\n",
    "# 4개의 특징(feature)를 가진 800000개 데이터\n",
    "print(Y_train.shape)\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f90240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성별</th>\n",
       "      <th>수축기혈압</th>\n",
       "      <th>이완기혈압</th>\n",
       "      <th>공복기혈당</th>\n",
       "      <th>체질량지수</th>\n",
       "      <th>연령대</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.220670</td>\n",
       "      <td>0.521092</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.626316</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.301676</td>\n",
       "      <td>0.595533</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.642105</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.284916</td>\n",
       "      <td>0.605459</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.248603</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.220670</td>\n",
       "      <td>0.568238</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   성별     수축기혈압     이완기혈압     공복기혈당     체질량지수       연령대\n",
       "0   2  0.631579  0.750000  0.220670  0.521092  0.571429\n",
       "1   2  0.626316  0.625000  0.301676  0.595533  0.857143\n",
       "2   1  0.642105  0.716667  0.284916  0.605459  0.571429\n",
       "3   1  0.631579  0.625000  0.248603  0.615385  0.428571\n",
       "4   2  0.531579  0.550000  0.220670  0.568238  0.428571"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a15c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP :\n",
    "    def __init__(self, given_X_train, given_Y_train,\n",
    "                 given_X_test, given_Y_test,\n",
    "                 given_num_layer_1, given_num_layer_2) :\n",
    "        self.X_train = given_X_train\n",
    "        self.Y_train = given_Y_train\n",
    "        self.X_test = given_X_test\n",
    "        self.Y_test = given_Y_test\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.num_class = 4 # class label 수\n",
    "        self.num_input = 6 # 입력값의 차원\n",
    "        self.num_layer_1 = given_num_layer_1 \n",
    "        self.num_layer_2 = given_num_layer_2\n",
    "        self.drop_out = 0.1 # drop-out rate\n",
    "        self.hidden_ftn = 'relu' # 은닉층 활성함수\n",
    "        self.output_ftn = 'softmax' # 출력층 활성함수\n",
    "        self.loss_ftn = 'categorical_crossentropy' # 손실함수\n",
    "        self.optimizer = 'adam' # 최적화 기법\n",
    "        self.metrics = 'accuracy' \n",
    "        self.batch_size = 100000 \n",
    "        self.epochs = 1000\n",
    "        self.validation_split = 0.2\n",
    "        self.score = list()\n",
    "        self.hist = tf.keras.callbacks.History()\n",
    "    \n",
    "    # 모델 생성 및 구현\n",
    "    def generate_model(self) : \n",
    "        # 첫 번째 은닉층\n",
    "        self.model.add(layers.Dense(self.num_layer_1, input_shape=(self.num_input,))) \n",
    "        self.model.add(layers.Activation(self.hidden_ftn))  \n",
    "        self.model.add(layers.Dropout(self.drop_out))        \n",
    "\n",
    "        # 두 번째 은닉층\n",
    "        self.model.add(layers.Dense(self.num_layer_2))            \n",
    "        self.model.add(layers.Activation(self.hidden_ftn))\n",
    "        self.model.add(layers.Dropout(self.drop_out))\n",
    "\n",
    "        # 출력층\n",
    "        self.model.add(layers.Dense(self.num_class))\n",
    "        self.model.add(layers.Activation(self.output_ftn))\n",
    "        \n",
    "        self.model.compile(loss = self.loss_ftn, \n",
    "                      optimizer = self.optimizer, \n",
    "                      metrics = [self.metrics]) \n",
    "    \n",
    "    # 모델 학습\n",
    "    def train_model(self) :\n",
    "        self.hist = self.model.fit(self.X_train, self.Y_train,batch_size = self.batch_size, \n",
    "                       epochs = self.epochs, # training epoch         \n",
    "                       validation_split = self.validation_split, # validation split\n",
    "                       # validation loss가 최저인 시점에서 epoch이 patience만큼 진행되는 동안 loss가 개선되지 않으면 학습 종료\n",
    "                       callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 15)], # early stopping\n",
    "                       verbose = 1)\n",
    "    \n",
    "    # 모델 평가\n",
    "    def evaluate_model(self) :\n",
    "        self.score = self.model.evaluate(self.X_test, self.Y_test)\n",
    "        return self.score\n",
    "    \n",
    "    def show_train_val_acc(self) :\n",
    "        fig, loss_ax = plt.subplots()\n",
    "        acc_ax = loss_ax.twinx()\n",
    "\n",
    "        loss_ax.plot(self.hist.history['loss'], 'y', label = 'train loss')\n",
    "        loss_ax.plot(self.hist.history['val_loss'], 'r', label = 'val loss')\n",
    "\n",
    "        acc_ax.plot(self.hist.history['accuracy'], 'b', label = 'train acc')\n",
    "        acc_ax.plot(self.hist.history['val_accuracy'], 'g', label = 'val acc')\n",
    "\n",
    "        loss_ax.set_xlabel('epoch')\n",
    "        loss_ax.set_ylabel('loss')\n",
    "        acc_ax.set_ylabel('accuray')\n",
    "\n",
    "        loss_ax.legend(loc='upper left')\n",
    "        acc_ax.legend(loc='lower left')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def show_model_summary(self) :\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    # 학습된 모델 저장\n",
    "    def save_model(self) :\n",
    "        self.model.save(\"dnn_term_project.h5\")\n",
    "        print(\"Model saved!\")\n",
    "        \n",
    "    def set_hidden_ftn(self, given_hidden_ftn) :\n",
    "        self.hidden_ftn = given_hidden_ftn\n",
    "        \n",
    "    def set_output_ftn(self, given_output_ftn, given_loss_ftn) :\n",
    "        self.output_ftn = given_output_ftn\n",
    "        self.loss_ftn = given_loss_ftn\n",
    "        \n",
    "    def set_dropout(self, given_dropout) :\n",
    "        self.dropout = given_dropout\n",
    "    \n",
    "    def set_optimizer(self, given_optimizer) :\n",
    "        self.optimizer = given_optimizer\n",
    "    \n",
    "    def set_batchsize(self, given_batch_size) :\n",
    "        self.batch_size = given_batch_size\n",
    "        \n",
    "    def set_epochs(self, given_epochs) :\n",
    "        self,epochs = given_epochs\n",
    "        \n",
    "    def set_validation_split(self, given_validation_split) :\n",
    "        self.validation_split = given_validation_split\n",
    "        \n",
    "    def get_all(self) :\n",
    "        print(\"은닉층 활성함수 : \", self.hidden_ftn) \n",
    "        print(\"출력층 활성함수: \" , self.output_ftn) \n",
    "        print(\"손실함수 : \", self.loss_ftn) \n",
    "        print(\"최적화 기법 : \" ,self.optimizer)\n",
    "    \n",
    "    def get_dropout(self) :\n",
    "        return self.dropout\n",
    "    \n",
    "    def get_optimizer(self) :\n",
    "        return self.optimizer\n",
    "    \n",
    "    def get_epochs(self) :\n",
    "        return self.epochs\n",
    "    \n",
    "    def get_validation_split(self) :\n",
    "        return self.validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e0c343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "7/7 [==============================] - 3s 275ms/step - loss: 1.2730 - accuracy: 0.5613 - val_loss: 1.1979 - val_accuracy: 0.7413\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 1.1708 - accuracy: 0.7105 - val_loss: 1.1118 - val_accuracy: 0.7413\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 1.0858 - accuracy: 0.7374 - val_loss: 1.0329 - val_accuracy: 0.7413\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 1.0105 - accuracy: 0.7404 - val_loss: 0.9642 - val_accuracy: 0.7413\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 0.9485 - accuracy: 0.7407 - val_loss: 0.9085 - val_accuracy: 0.7413\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 0.9043 - accuracy: 0.7407 - val_loss: 0.8733 - val_accuracy: 0.7413\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.8807 - accuracy: 0.7407 - val_loss: 0.8563 - val_accuracy: 0.7413\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.8685 - accuracy: 0.7407 - val_loss: 0.8454 - val_accuracy: 0.7413\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.8585 - accuracy: 0.7407 - val_loss: 0.8380 - val_accuracy: 0.7413\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.8523 - accuracy: 0.7407 - val_loss: 0.8332 - val_accuracy: 0.7413\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.8475 - accuracy: 0.7407 - val_loss: 0.8288 - val_accuracy: 0.7413\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 2s 236ms/step - loss: 0.8433 - accuracy: 0.7407 - val_loss: 0.8232 - val_accuracy: 0.7413\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 2s 293ms/step - loss: 0.8385 - accuracy: 0.7407 - val_loss: 0.8180 - val_accuracy: 0.7413\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 2s 336ms/step - loss: 0.8326 - accuracy: 0.7407 - val_loss: 0.8116 - val_accuracy: 0.7413\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 2s 232ms/step - loss: 0.8262 - accuracy: 0.7407 - val_loss: 0.8049 - val_accuracy: 0.7413\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.8193 - accuracy: 0.7407 - val_loss: 0.7976 - val_accuracy: 0.7413\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 2s 236ms/step - loss: 0.8122 - accuracy: 0.7407 - val_loss: 0.7895 - val_accuracy: 0.7413\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 0.8044 - accuracy: 0.7406 - val_loss: 0.7814 - val_accuracy: 0.7413\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 1s 210ms/step - loss: 0.7973 - accuracy: 0.7406 - val_loss: 0.7732 - val_accuracy: 0.7413\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.7888 - accuracy: 0.7406 - val_loss: 0.7649 - val_accuracy: 0.7413\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.7813 - accuracy: 0.7405 - val_loss: 0.7564 - val_accuracy: 0.7413\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.7735 - accuracy: 0.7406 - val_loss: 0.7479 - val_accuracy: 0.7413\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.7656 - accuracy: 0.7403 - val_loss: 0.7397 - val_accuracy: 0.7413\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.7585 - accuracy: 0.7404 - val_loss: 0.7317 - val_accuracy: 0.7413\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.7504 - accuracy: 0.7401 - val_loss: 0.7241 - val_accuracy: 0.7410\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 1s 213ms/step - loss: 0.7434 - accuracy: 0.7403 - val_loss: 0.7170 - val_accuracy: 0.7402\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 1s 209ms/step - loss: 0.7365 - accuracy: 0.7403 - val_loss: 0.7105 - val_accuracy: 0.7393\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 1s 213ms/step - loss: 0.7300 - accuracy: 0.7406 - val_loss: 0.7039 - val_accuracy: 0.7402\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.7240 - accuracy: 0.7410 - val_loss: 0.6977 - val_accuracy: 0.7413\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 0.7180 - accuracy: 0.7417 - val_loss: 0.6926 - val_accuracy: 0.7422\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.7127 - accuracy: 0.7423 - val_loss: 0.6880 - val_accuracy: 0.7433\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 0.7082 - accuracy: 0.7420 - val_loss: 0.6836 - val_accuracy: 0.7454\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.7039 - accuracy: 0.7424 - val_loss: 0.6796 - val_accuracy: 0.7471\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.6999 - accuracy: 0.7424 - val_loss: 0.6759 - val_accuracy: 0.7477\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 0.6962 - accuracy: 0.7428 - val_loss: 0.6722 - val_accuracy: 0.7488\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.6920 - accuracy: 0.7431 - val_loss: 0.6688 - val_accuracy: 0.7489\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 0.6893 - accuracy: 0.7432 - val_loss: 0.6654 - val_accuracy: 0.7492\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.6856 - accuracy: 0.7435 - val_loss: 0.6621 - val_accuracy: 0.7493\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 2s 222ms/step - loss: 0.6823 - accuracy: 0.7439 - val_loss: 0.6590 - val_accuracy: 0.7494\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 0.6788 - accuracy: 0.7441 - val_loss: 0.6558 - val_accuracy: 0.7494\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 2s 219ms/step - loss: 0.6755 - accuracy: 0.7446 - val_loss: 0.6528 - val_accuracy: 0.7495\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 2s 202ms/step - loss: 0.6726 - accuracy: 0.7452 - val_loss: 0.6498 - val_accuracy: 0.7496\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 0.6696 - accuracy: 0.7457 - val_loss: 0.6468 - val_accuracy: 0.7498\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.6667 - accuracy: 0.7459 - val_loss: 0.6438 - val_accuracy: 0.7500\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 2s 232ms/step - loss: 0.6638 - accuracy: 0.7467 - val_loss: 0.6408 - val_accuracy: 0.7504\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 1s 203ms/step - loss: 0.6609 - accuracy: 0.7469 - val_loss: 0.6379 - val_accuracy: 0.7511\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.6581 - accuracy: 0.7477 - val_loss: 0.6350 - val_accuracy: 0.7517\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.6550 - accuracy: 0.7486 - val_loss: 0.6323 - val_accuracy: 0.7526\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.6528 - accuracy: 0.7486 - val_loss: 0.6296 - val_accuracy: 0.7535\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.6501 - accuracy: 0.7490 - val_loss: 0.6270 - val_accuracy: 0.7543\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.6473 - accuracy: 0.7503 - val_loss: 0.6245 - val_accuracy: 0.7551\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 0.6450 - accuracy: 0.7501 - val_loss: 0.6220 - val_accuracy: 0.7559\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.6424 - accuracy: 0.7508 - val_loss: 0.6196 - val_accuracy: 0.7567\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 1s 151ms/step - loss: 0.6404 - accuracy: 0.7510 - val_loss: 0.6173 - val_accuracy: 0.7573\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.6382 - accuracy: 0.7518 - val_loss: 0.6151 - val_accuracy: 0.7579\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 1s 211ms/step - loss: 0.6354 - accuracy: 0.7529 - val_loss: 0.6128 - val_accuracy: 0.7589\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 1s 205ms/step - loss: 0.6338 - accuracy: 0.7526 - val_loss: 0.6107 - val_accuracy: 0.7594\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 0.6319 - accuracy: 0.7533 - val_loss: 0.6087 - val_accuracy: 0.7601\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.6299 - accuracy: 0.7536 - val_loss: 0.6068 - val_accuracy: 0.7607\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 2s 229ms/step - loss: 0.6283 - accuracy: 0.7542 - val_loss: 0.6049 - val_accuracy: 0.7614\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 2s 227ms/step - loss: 0.6258 - accuracy: 0.7552 - val_loss: 0.6033 - val_accuracy: 0.7621\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 2s 253ms/step - loss: 0.6245 - accuracy: 0.7555 - val_loss: 0.6015 - val_accuracy: 0.7632\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 2s 246ms/step - loss: 0.6225 - accuracy: 0.7557 - val_loss: 0.5999 - val_accuracy: 0.7638\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 2s 222ms/step - loss: 0.6209 - accuracy: 0.7565 - val_loss: 0.5983 - val_accuracy: 0.7645\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 2s 249ms/step - loss: 0.6192 - accuracy: 0.7573 - val_loss: 0.5968 - val_accuracy: 0.7649\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 2s 222ms/step - loss: 0.6181 - accuracy: 0.7569 - val_loss: 0.5956 - val_accuracy: 0.7646\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 2s 258ms/step - loss: 0.6165 - accuracy: 0.7580 - val_loss: 0.5942 - val_accuracy: 0.7654\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 2s 211ms/step - loss: 0.6154 - accuracy: 0.7578 - val_loss: 0.5929 - val_accuracy: 0.7662\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 1s 207ms/step - loss: 0.6140 - accuracy: 0.7584 - val_loss: 0.5919 - val_accuracy: 0.7667\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 2s 216ms/step - loss: 0.6130 - accuracy: 0.7589 - val_loss: 0.5907 - val_accuracy: 0.7670\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.6115 - accuracy: 0.7591 - val_loss: 0.5897 - val_accuracy: 0.7673\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 2s 250ms/step - loss: 0.6104 - accuracy: 0.7595 - val_loss: 0.5889 - val_accuracy: 0.7675\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 2s 265ms/step - loss: 0.6096 - accuracy: 0.7600 - val_loss: 0.5878 - val_accuracy: 0.7681\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 2s 246ms/step - loss: 0.6089 - accuracy: 0.7599 - val_loss: 0.5871 - val_accuracy: 0.7682\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 2s 265ms/step - loss: 0.6075 - accuracy: 0.7608 - val_loss: 0.5863 - val_accuracy: 0.7686\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.6067 - accuracy: 0.7609 - val_loss: 0.5854 - val_accuracy: 0.7690\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 1s 210ms/step - loss: 0.6052 - accuracy: 0.7609 - val_loss: 0.5844 - val_accuracy: 0.7696\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.6047 - accuracy: 0.7613 - val_loss: 0.5838 - val_accuracy: 0.7695\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.6037 - accuracy: 0.7616 - val_loss: 0.5832 - val_accuracy: 0.7699\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.6033 - accuracy: 0.7615 - val_loss: 0.5825 - val_accuracy: 0.7702\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.6026 - accuracy: 0.7620 - val_loss: 0.5820 - val_accuracy: 0.7705\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.6015 - accuracy: 0.7620 - val_loss: 0.5814 - val_accuracy: 0.7708\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.6008 - accuracy: 0.7623 - val_loss: 0.5810 - val_accuracy: 0.7709\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.6005 - accuracy: 0.7627 - val_loss: 0.5806 - val_accuracy: 0.7706\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.6000 - accuracy: 0.7628 - val_loss: 0.5800 - val_accuracy: 0.7712\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5998 - accuracy: 0.7632 - val_loss: 0.5796 - val_accuracy: 0.7714\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 0.5990 - accuracy: 0.7636 - val_loss: 0.5794 - val_accuracy: 0.7712\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 1s 210ms/step - loss: 0.5985 - accuracy: 0.7631 - val_loss: 0.5789 - val_accuracy: 0.7714\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5980 - accuracy: 0.7635 - val_loss: 0.5788 - val_accuracy: 0.7712\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 1s 210ms/step - loss: 0.5974 - accuracy: 0.7643 - val_loss: 0.5784 - val_accuracy: 0.7715\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.5970 - accuracy: 0.7637 - val_loss: 0.5780 - val_accuracy: 0.7717\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.5970 - accuracy: 0.7637 - val_loss: 0.5777 - val_accuracy: 0.7718\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 1s 146ms/step - loss: 0.5962 - accuracy: 0.7643 - val_loss: 0.5773 - val_accuracy: 0.7720\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.5955 - accuracy: 0.7646 - val_loss: 0.5770 - val_accuracy: 0.7719\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 1s 205ms/step - loss: 0.5952 - accuracy: 0.7641 - val_loss: 0.5766 - val_accuracy: 0.7725\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 1s 214ms/step - loss: 0.5951 - accuracy: 0.7642 - val_loss: 0.5766 - val_accuracy: 0.7721\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.5949 - accuracy: 0.7641 - val_loss: 0.5764 - val_accuracy: 0.7722\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.5941 - accuracy: 0.7648 - val_loss: 0.5760 - val_accuracy: 0.7725\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 1s 210ms/step - loss: 0.5945 - accuracy: 0.7649 - val_loss: 0.5758 - val_accuracy: 0.7725\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 1s 213ms/step - loss: 0.5939 - accuracy: 0.7646 - val_loss: 0.5755 - val_accuracy: 0.7728\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.5935 - accuracy: 0.7654 - val_loss: 0.5753 - val_accuracy: 0.7728\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 0.5928 - accuracy: 0.7650 - val_loss: 0.5749 - val_accuracy: 0.7733\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5924 - accuracy: 0.7648 - val_loss: 0.5750 - val_accuracy: 0.7730\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.5926 - accuracy: 0.7654 - val_loss: 0.5745 - val_accuracy: 0.7731\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 2s 232ms/step - loss: 0.5923 - accuracy: 0.7649 - val_loss: 0.5744 - val_accuracy: 0.7731\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 0.5918 - accuracy: 0.7657 - val_loss: 0.5744 - val_accuracy: 0.7730\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 1s 212ms/step - loss: 0.5915 - accuracy: 0.7658 - val_loss: 0.5740 - val_accuracy: 0.7732\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 1s 213ms/step - loss: 0.5908 - accuracy: 0.7660 - val_loss: 0.5738 - val_accuracy: 0.7734\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 1s 147ms/step - loss: 0.5909 - accuracy: 0.7659 - val_loss: 0.5737 - val_accuracy: 0.7732\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 1s 148ms/step - loss: 0.5906 - accuracy: 0.7656 - val_loss: 0.5735 - val_accuracy: 0.7733\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.5904 - accuracy: 0.7663 - val_loss: 0.5735 - val_accuracy: 0.7734\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.5902 - accuracy: 0.7661 - val_loss: 0.5732 - val_accuracy: 0.7735\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.5897 - accuracy: 0.7662 - val_loss: 0.5731 - val_accuracy: 0.7735\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 1s 134ms/step - loss: 0.5895 - accuracy: 0.7658 - val_loss: 0.5730 - val_accuracy: 0.7733\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 214ms/step - loss: 0.5897 - accuracy: 0.7664 - val_loss: 0.5728 - val_accuracy: 0.7735\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 1s 207ms/step - loss: 0.5889 - accuracy: 0.7667 - val_loss: 0.5727 - val_accuracy: 0.7737\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 0.5886 - accuracy: 0.7671 - val_loss: 0.5727 - val_accuracy: 0.7734\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.5887 - accuracy: 0.7669 - val_loss: 0.5725 - val_accuracy: 0.7737\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 2s 239ms/step - loss: 0.5884 - accuracy: 0.7664 - val_loss: 0.5723 - val_accuracy: 0.7741\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.5879 - accuracy: 0.7668 - val_loss: 0.5722 - val_accuracy: 0.7736\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.5883 - accuracy: 0.7667 - val_loss: 0.5722 - val_accuracy: 0.7738\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5877 - accuracy: 0.7672 - val_loss: 0.5723 - val_accuracy: 0.7736\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 1s 148ms/step - loss: 0.5875 - accuracy: 0.7674 - val_loss: 0.5719 - val_accuracy: 0.7739\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.5873 - accuracy: 0.7671 - val_loss: 0.5718 - val_accuracy: 0.7738\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 0.5874 - accuracy: 0.7674 - val_loss: 0.5718 - val_accuracy: 0.7739\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 1s 141ms/step - loss: 0.5874 - accuracy: 0.7671 - val_loss: 0.5717 - val_accuracy: 0.7739\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.5870 - accuracy: 0.7670 - val_loss: 0.5718 - val_accuracy: 0.7738\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 0.5873 - accuracy: 0.7670 - val_loss: 0.5717 - val_accuracy: 0.7740\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.5864 - accuracy: 0.7674 - val_loss: 0.5715 - val_accuracy: 0.7739\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 1s 142ms/step - loss: 0.5867 - accuracy: 0.7673 - val_loss: 0.5714 - val_accuracy: 0.7739\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.5861 - accuracy: 0.7676 - val_loss: 0.5714 - val_accuracy: 0.7736\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 1s 163ms/step - loss: 0.5867 - accuracy: 0.7671 - val_loss: 0.5714 - val_accuracy: 0.7740\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 1s 146ms/step - loss: 0.5862 - accuracy: 0.7675 - val_loss: 0.5713 - val_accuracy: 0.7738\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 0.5863 - accuracy: 0.7677 - val_loss: 0.5713 - val_accuracy: 0.7740\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 0.5859 - accuracy: 0.7678 - val_loss: 0.5714 - val_accuracy: 0.7740\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.5861 - accuracy: 0.7674 - val_loss: 0.5713 - val_accuracy: 0.7738\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.5856 - accuracy: 0.7675 - val_loss: 0.5711 - val_accuracy: 0.7739\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.5856 - accuracy: 0.7677 - val_loss: 0.5709 - val_accuracy: 0.7738\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 0.5854 - accuracy: 0.7680 - val_loss: 0.5710 - val_accuracy: 0.7740\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 0.5850 - accuracy: 0.7685 - val_loss: 0.5707 - val_accuracy: 0.7740\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 0.5853 - accuracy: 0.7679 - val_loss: 0.5708 - val_accuracy: 0.7740\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 1s 154ms/step - loss: 0.5851 - accuracy: 0.7683 - val_loss: 0.5708 - val_accuracy: 0.7740\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 1s 158ms/step - loss: 0.5849 - accuracy: 0.7680 - val_loss: 0.5707 - val_accuracy: 0.7740\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 0.5842 - accuracy: 0.7682 - val_loss: 0.5705 - val_accuracy: 0.7740\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 0.5843 - accuracy: 0.7683 - val_loss: 0.5705 - val_accuracy: 0.7741\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.5844 - accuracy: 0.7681 - val_loss: 0.5704 - val_accuracy: 0.7741\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 1s 146ms/step - loss: 0.5839 - accuracy: 0.7687 - val_loss: 0.5703 - val_accuracy: 0.7740\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.5841 - accuracy: 0.7682 - val_loss: 0.5704 - val_accuracy: 0.7741\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 0.5841 - accuracy: 0.7685 - val_loss: 0.5703 - val_accuracy: 0.7741\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.5836 - accuracy: 0.7689 - val_loss: 0.5703 - val_accuracy: 0.7742\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.5841 - accuracy: 0.7685 - val_loss: 0.5703 - val_accuracy: 0.7740\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.5834 - accuracy: 0.7686 - val_loss: 0.5701 - val_accuracy: 0.7742\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 0.5836 - accuracy: 0.7688 - val_loss: 0.5699 - val_accuracy: 0.7742\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.5836 - accuracy: 0.7686 - val_loss: 0.5701 - val_accuracy: 0.7740\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.5837 - accuracy: 0.7687 - val_loss: 0.5701 - val_accuracy: 0.7742\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 1s 147ms/step - loss: 0.5832 - accuracy: 0.7686 - val_loss: 0.5698 - val_accuracy: 0.7742\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 0.5833 - accuracy: 0.7684 - val_loss: 0.5698 - val_accuracy: 0.7741\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 1s 151ms/step - loss: 0.5834 - accuracy: 0.7688 - val_loss: 0.5698 - val_accuracy: 0.7741\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.5832 - accuracy: 0.7689 - val_loss: 0.5697 - val_accuracy: 0.7740\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 1s 162ms/step - loss: 0.5833 - accuracy: 0.7686 - val_loss: 0.5698 - val_accuracy: 0.7741\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 1s 158ms/step - loss: 0.5827 - accuracy: 0.7688 - val_loss: 0.5697 - val_accuracy: 0.7741\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 0.5832 - accuracy: 0.7685 - val_loss: 0.5696 - val_accuracy: 0.7741\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 0.5826 - accuracy: 0.7688 - val_loss: 0.5696 - val_accuracy: 0.7742\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.5827 - accuracy: 0.7688 - val_loss: 0.5696 - val_accuracy: 0.7744\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.5825 - accuracy: 0.7690 - val_loss: 0.5697 - val_accuracy: 0.7743\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.5823 - accuracy: 0.7691 - val_loss: 0.5696 - val_accuracy: 0.7744\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 0.5824 - accuracy: 0.7691 - val_loss: 0.5694 - val_accuracy: 0.7745\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 1s 142ms/step - loss: 0.5822 - accuracy: 0.7692 - val_loss: 0.5693 - val_accuracy: 0.7744\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.5822 - accuracy: 0.7688 - val_loss: 0.5695 - val_accuracy: 0.7743\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 1s 151ms/step - loss: 0.5821 - accuracy: 0.7691 - val_loss: 0.5695 - val_accuracy: 0.7742\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5820 - accuracy: 0.7693 - val_loss: 0.5694 - val_accuracy: 0.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.5814 - accuracy: 0.7695 - val_loss: 0.5693 - val_accuracy: 0.7743\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.5818 - accuracy: 0.7691 - val_loss: 0.5693 - val_accuracy: 0.7742\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 1s 162ms/step - loss: 0.5815 - accuracy: 0.7693 - val_loss: 0.5692 - val_accuracy: 0.7744\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.5819 - accuracy: 0.7691 - val_loss: 0.5692 - val_accuracy: 0.7743\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.5813 - accuracy: 0.7692 - val_loss: 0.5693 - val_accuracy: 0.7742\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.5812 - accuracy: 0.7698 - val_loss: 0.5694 - val_accuracy: 0.7742\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.5813 - accuracy: 0.7694 - val_loss: 0.5694 - val_accuracy: 0.7742\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.5811 - accuracy: 0.7695 - val_loss: 0.5692 - val_accuracy: 0.7742\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.5812 - accuracy: 0.7696 - val_loss: 0.5690 - val_accuracy: 0.7743\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.5813 - accuracy: 0.7695 - val_loss: 0.5690 - val_accuracy: 0.7745\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 1s 211ms/step - loss: 0.5810 - accuracy: 0.7697 - val_loss: 0.5689 - val_accuracy: 0.7744\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.5808 - accuracy: 0.7697 - val_loss: 0.5688 - val_accuracy: 0.7745\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 1s 219ms/step - loss: 0.5807 - accuracy: 0.7695 - val_loss: 0.5690 - val_accuracy: 0.7743\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5809 - accuracy: 0.7697 - val_loss: 0.5689 - val_accuracy: 0.7742\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.5808 - accuracy: 0.7696 - val_loss: 0.5688 - val_accuracy: 0.7744\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 0.5805 - accuracy: 0.7699 - val_loss: 0.5688 - val_accuracy: 0.7747\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5804 - accuracy: 0.7699 - val_loss: 0.5688 - val_accuracy: 0.7745\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 0.5804 - accuracy: 0.7698 - val_loss: 0.5687 - val_accuracy: 0.7746\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 1s 215ms/step - loss: 0.5805 - accuracy: 0.7698 - val_loss: 0.5686 - val_accuracy: 0.7744\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 0.5804 - accuracy: 0.7695 - val_loss: 0.5687 - val_accuracy: 0.7745\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.5803 - accuracy: 0.7698 - val_loss: 0.5686 - val_accuracy: 0.7747\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.5800 - accuracy: 0.7699 - val_loss: 0.5685 - val_accuracy: 0.7745\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5799 - accuracy: 0.7698 - val_loss: 0.5684 - val_accuracy: 0.7747\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.5798 - accuracy: 0.7698 - val_loss: 0.5685 - val_accuracy: 0.7745\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 1s 216ms/step - loss: 0.5800 - accuracy: 0.7696 - val_loss: 0.5683 - val_accuracy: 0.7747\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5799 - accuracy: 0.7700 - val_loss: 0.5685 - val_accuracy: 0.7744\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 2s 245ms/step - loss: 0.5799 - accuracy: 0.7699 - val_loss: 0.5685 - val_accuracy: 0.7746\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 1s 163ms/step - loss: 0.5798 - accuracy: 0.7702 - val_loss: 0.5683 - val_accuracy: 0.7746\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.5795 - accuracy: 0.7701 - val_loss: 0.5683 - val_accuracy: 0.7745\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.5797 - accuracy: 0.7699 - val_loss: 0.5682 - val_accuracy: 0.7746\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.5795 - accuracy: 0.7702 - val_loss: 0.5682 - val_accuracy: 0.7747\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 0.5793 - accuracy: 0.7705 - val_loss: 0.5682 - val_accuracy: 0.7745\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.5795 - accuracy: 0.7703 - val_loss: 0.5681 - val_accuracy: 0.7748\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.5793 - accuracy: 0.7699 - val_loss: 0.5680 - val_accuracy: 0.7748\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5791 - accuracy: 0.7704 - val_loss: 0.5680 - val_accuracy: 0.7747\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 1s 209ms/step - loss: 0.5793 - accuracy: 0.7700 - val_loss: 0.5680 - val_accuracy: 0.7747\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.5795 - accuracy: 0.7701 - val_loss: 0.5680 - val_accuracy: 0.7748\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5793 - accuracy: 0.7699 - val_loss: 0.5680 - val_accuracy: 0.7747\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.5795 - accuracy: 0.7702 - val_loss: 0.5679 - val_accuracy: 0.7747\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.5789 - accuracy: 0.7704 - val_loss: 0.5680 - val_accuracy: 0.7748\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5787 - accuracy: 0.7707 - val_loss: 0.5680 - val_accuracy: 0.7745\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 1s 151ms/step - loss: 0.5789 - accuracy: 0.7705 - val_loss: 0.5679 - val_accuracy: 0.7748\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5792 - accuracy: 0.7699 - val_loss: 0.5679 - val_accuracy: 0.7746\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.5789 - accuracy: 0.7706 - val_loss: 0.5679 - val_accuracy: 0.7745\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.5792 - accuracy: 0.7704 - val_loss: 0.5679 - val_accuracy: 0.7746\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 1s 142ms/step - loss: 0.5789 - accuracy: 0.7706 - val_loss: 0.5679 - val_accuracy: 0.7746\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.5787 - accuracy: 0.7705 - val_loss: 0.5679 - val_accuracy: 0.7746\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.5790 - accuracy: 0.7705 - val_loss: 0.5677 - val_accuracy: 0.7747\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 0.5786 - accuracy: 0.7705 - val_loss: 0.5677 - val_accuracy: 0.7745\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 0.5786 - accuracy: 0.7703 - val_loss: 0.5677 - val_accuracy: 0.7747\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.5787 - accuracy: 0.7707 - val_loss: 0.5677 - val_accuracy: 0.7749\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.5784 - accuracy: 0.7701 - val_loss: 0.5677 - val_accuracy: 0.7747\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 1s 151ms/step - loss: 0.5782 - accuracy: 0.7708 - val_loss: 0.5677 - val_accuracy: 0.7746\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5780 - accuracy: 0.7709 - val_loss: 0.5677 - val_accuracy: 0.7747\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 0.5784 - accuracy: 0.7707 - val_loss: 0.5677 - val_accuracy: 0.7745\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.5782 - accuracy: 0.7709 - val_loss: 0.5676 - val_accuracy: 0.7749\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 1s 151ms/step - loss: 0.5783 - accuracy: 0.7707 - val_loss: 0.5675 - val_accuracy: 0.7749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5783 - accuracy: 0.7706 - val_loss: 0.5676 - val_accuracy: 0.7745\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 0.5784 - accuracy: 0.7707 - val_loss: 0.5675 - val_accuracy: 0.7748\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.5783 - accuracy: 0.7706 - val_loss: 0.5676 - val_accuracy: 0.7745\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.5779 - accuracy: 0.7705 - val_loss: 0.5676 - val_accuracy: 0.7746\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 0.5780 - accuracy: 0.7708 - val_loss: 0.5674 - val_accuracy: 0.7749\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5779 - accuracy: 0.7711 - val_loss: 0.5673 - val_accuracy: 0.7749\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.5783 - accuracy: 0.7710 - val_loss: 0.5673 - val_accuracy: 0.7750\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.5779 - accuracy: 0.7707 - val_loss: 0.5673 - val_accuracy: 0.7750\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.5780 - accuracy: 0.7710 - val_loss: 0.5674 - val_accuracy: 0.7748\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.5777 - accuracy: 0.7706 - val_loss: 0.5674 - val_accuracy: 0.7748\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.5776 - accuracy: 0.7709 - val_loss: 0.5673 - val_accuracy: 0.7748\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 0.5778 - accuracy: 0.7710 - val_loss: 0.5673 - val_accuracy: 0.7746\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.5781 - accuracy: 0.7708 - val_loss: 0.5674 - val_accuracy: 0.7746\n",
      "Epoch 242/1000\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5776 - accuracy: 0.7710 - val_loss: 0.5673 - val_accuracy: 0.7749\n",
      "Epoch 243/1000\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 0.5777 - accuracy: 0.7709 - val_loss: 0.5672 - val_accuracy: 0.7747\n",
      "Epoch 244/1000\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5777 - accuracy: 0.7709 - val_loss: 0.5674 - val_accuracy: 0.7745\n",
      "Epoch 245/1000\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.5777 - accuracy: 0.7710 - val_loss: 0.5673 - val_accuracy: 0.7749\n",
      "Epoch 246/1000\n",
      "7/7 [==============================] - 2s 225ms/step - loss: 0.5777 - accuracy: 0.7709 - val_loss: 0.5671 - val_accuracy: 0.7749\n",
      "Epoch 247/1000\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5780 - accuracy: 0.7708 - val_loss: 0.5671 - val_accuracy: 0.7749\n",
      "Epoch 248/1000\n",
      "7/7 [==============================] - 2s 241ms/step - loss: 0.5774 - accuracy: 0.7713 - val_loss: 0.5672 - val_accuracy: 0.7749\n",
      "Epoch 249/1000\n",
      "7/7 [==============================] - 1s 155ms/step - loss: 0.5775 - accuracy: 0.7710 - val_loss: 0.5672 - val_accuracy: 0.7748\n",
      "Epoch 250/1000\n",
      "7/7 [==============================] - 1s 163ms/step - loss: 0.5774 - accuracy: 0.7709 - val_loss: 0.5674 - val_accuracy: 0.7747\n",
      "Epoch 251/1000\n",
      "7/7 [==============================] - 1s 155ms/step - loss: 0.5774 - accuracy: 0.7710 - val_loss: 0.5672 - val_accuracy: 0.7748\n",
      "Epoch 252/1000\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 0.5775 - accuracy: 0.7710 - val_loss: 0.5670 - val_accuracy: 0.7750\n",
      "Epoch 253/1000\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.5773 - accuracy: 0.7714 - val_loss: 0.5670 - val_accuracy: 0.7751\n",
      "Epoch 254/1000\n",
      "7/7 [==============================] - 1s 211ms/step - loss: 0.5774 - accuracy: 0.7715 - val_loss: 0.5670 - val_accuracy: 0.7751\n",
      "Epoch 255/1000\n",
      "7/7 [==============================] - 2s 245ms/step - loss: 0.5775 - accuracy: 0.7709 - val_loss: 0.5670 - val_accuracy: 0.7750\n",
      "Epoch 256/1000\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 0.5773 - accuracy: 0.7709 - val_loss: 0.5670 - val_accuracy: 0.7749\n",
      "Epoch 257/1000\n",
      "7/7 [==============================] - 1s 203ms/step - loss: 0.5772 - accuracy: 0.7712 - val_loss: 0.5670 - val_accuracy: 0.7749\n",
      "Epoch 258/1000\n",
      "7/7 [==============================] - 1s 212ms/step - loss: 0.5772 - accuracy: 0.7712 - val_loss: 0.5670 - val_accuracy: 0.7748\n",
      "Epoch 259/1000\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.5772 - accuracy: 0.7713 - val_loss: 0.5669 - val_accuracy: 0.7752\n",
      "Epoch 260/1000\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 0.5775 - accuracy: 0.7713 - val_loss: 0.5669 - val_accuracy: 0.7750\n",
      "Epoch 261/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.5771 - accuracy: 0.7715 - val_loss: 0.5670 - val_accuracy: 0.7749\n",
      "Epoch 262/1000\n",
      "7/7 [==============================] - 1s 155ms/step - loss: 0.5769 - accuracy: 0.7715 - val_loss: 0.5669 - val_accuracy: 0.7748\n",
      "Epoch 263/1000\n",
      "7/7 [==============================] - 1s 221ms/step - loss: 0.5770 - accuracy: 0.7714 - val_loss: 0.5669 - val_accuracy: 0.7750\n",
      "Epoch 264/1000\n",
      "7/7 [==============================] - 1s 146ms/step - loss: 0.5770 - accuracy: 0.7713 - val_loss: 0.5670 - val_accuracy: 0.7747\n",
      "Epoch 265/1000\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.5767 - accuracy: 0.7712 - val_loss: 0.5671 - val_accuracy: 0.7747\n",
      "Epoch 266/1000\n",
      "7/7 [==============================] - 1s 148ms/step - loss: 0.5770 - accuracy: 0.7711 - val_loss: 0.5669 - val_accuracy: 0.7749\n",
      "Epoch 267/1000\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.5766 - accuracy: 0.7718 - val_loss: 0.5669 - val_accuracy: 0.7750\n",
      "Epoch 268/1000\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.5768 - accuracy: 0.7717 - val_loss: 0.5668 - val_accuracy: 0.7749\n",
      "Epoch 269/1000\n",
      "7/7 [==============================] - 1s 162ms/step - loss: 0.5767 - accuracy: 0.7715 - val_loss: 0.5670 - val_accuracy: 0.7748\n",
      "Epoch 270/1000\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.5767 - accuracy: 0.7715 - val_loss: 0.5669 - val_accuracy: 0.7748\n",
      "Epoch 271/1000\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.5767 - accuracy: 0.7720 - val_loss: 0.5667 - val_accuracy: 0.7751\n",
      "Epoch 272/1000\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5767 - accuracy: 0.7715 - val_loss: 0.5667 - val_accuracy: 0.7750\n",
      "Epoch 273/1000\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.5767 - accuracy: 0.7715 - val_loss: 0.5668 - val_accuracy: 0.7749\n",
      "Epoch 274/1000\n",
      "7/7 [==============================] - 1s 219ms/step - loss: 0.5766 - accuracy: 0.7715 - val_loss: 0.5667 - val_accuracy: 0.7754\n",
      "Epoch 275/1000\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.5767 - accuracy: 0.7716 - val_loss: 0.5668 - val_accuracy: 0.7748\n",
      "Epoch 276/1000\n",
      "7/7 [==============================] - 2s 218ms/step - loss: 0.5767 - accuracy: 0.7714 - val_loss: 0.5669 - val_accuracy: 0.7748\n",
      "Epoch 277/1000\n",
      "7/7 [==============================] - 1s 208ms/step - loss: 0.5768 - accuracy: 0.7716 - val_loss: 0.5669 - val_accuracy: 0.7750\n",
      "Epoch 278/1000\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5767 - accuracy: 0.7717 - val_loss: 0.5669 - val_accuracy: 0.7747\n",
      "Epoch 279/1000\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.5769 - accuracy: 0.7715 - val_loss: 0.5666 - val_accuracy: 0.7754\n",
      "Epoch 280/1000\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.5765 - accuracy: 0.7714 - val_loss: 0.5666 - val_accuracy: 0.7753\n",
      "Epoch 281/1000\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5765 - accuracy: 0.7716 - val_loss: 0.5666 - val_accuracy: 0.7750\n",
      "Epoch 282/1000\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.5762 - accuracy: 0.7717 - val_loss: 0.5666 - val_accuracy: 0.7752\n",
      "Epoch 283/1000\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.5762 - accuracy: 0.7716 - val_loss: 0.5666 - val_accuracy: 0.7750\n",
      "Epoch 284/1000\n",
      "7/7 [==============================] - 1s 212ms/step - loss: 0.5763 - accuracy: 0.7716 - val_loss: 0.5666 - val_accuracy: 0.7752\n",
      "Epoch 285/1000\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.5764 - accuracy: 0.7716 - val_loss: 0.5666 - val_accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 0.5762 - accuracy: 0.7718 - val_loss: 0.5665 - val_accuracy: 0.7753\n",
      "Epoch 287/1000\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.5762 - accuracy: 0.7715 - val_loss: 0.5666 - val_accuracy: 0.7750\n",
      "Epoch 288/1000\n",
      "7/7 [==============================] - 1s 154ms/step - loss: 0.5764 - accuracy: 0.7717 - val_loss: 0.5667 - val_accuracy: 0.7752\n",
      "Epoch 289/1000\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.5762 - accuracy: 0.7717 - val_loss: 0.5666 - val_accuracy: 0.7753\n",
      "Epoch 290/1000\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 0.5767 - accuracy: 0.7717 - val_loss: 0.5667 - val_accuracy: 0.7749\n",
      "Epoch 291/1000\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 0.5761 - accuracy: 0.7714 - val_loss: 0.5669 - val_accuracy: 0.7746\n",
      "Epoch 292/1000\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5762 - accuracy: 0.7718 - val_loss: 0.5668 - val_accuracy: 0.7747\n",
      "Epoch 293/1000\n",
      "7/7 [==============================] - 2s 246ms/step - loss: 0.5763 - accuracy: 0.7718 - val_loss: 0.5666 - val_accuracy: 0.7751\n",
      "Epoch 294/1000\n",
      "7/7 [==============================] - 1s 215ms/step - loss: 0.5761 - accuracy: 0.7721 - val_loss: 0.5665 - val_accuracy: 0.7752\n",
      "Epoch 295/1000\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.5762 - accuracy: 0.7718 - val_loss: 0.5665 - val_accuracy: 0.7750\n",
      "Epoch 296/1000\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.5761 - accuracy: 0.7716 - val_loss: 0.5666 - val_accuracy: 0.7752\n",
      "Epoch 297/1000\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 0.5761 - accuracy: 0.7718 - val_loss: 0.5668 - val_accuracy: 0.7747\n",
      "Epoch 298/1000\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.5764 - accuracy: 0.7717 - val_loss: 0.5666 - val_accuracy: 0.7750\n",
      "Epoch 299/1000\n",
      "7/7 [==============================] - 2s 267ms/step - loss: 0.5760 - accuracy: 0.7718 - val_loss: 0.5667 - val_accuracy: 0.7749\n",
      "Epoch 300/1000\n",
      "7/7 [==============================] - 2s 243ms/step - loss: 0.5761 - accuracy: 0.7715 - val_loss: 0.5667 - val_accuracy: 0.7750\n",
      "Epoch 301/1000\n",
      "7/7 [==============================] - 1s 205ms/step - loss: 0.5758 - accuracy: 0.7718 - val_loss: 0.5666 - val_accuracy: 0.7749\n",
      "Epoch 302/1000\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5757 - accuracy: 0.7718 - val_loss: 0.5665 - val_accuracy: 0.7753\n",
      "Epoch 303/1000\n",
      "7/7 [==============================] - 1s 148ms/step - loss: 0.5757 - accuracy: 0.7718 - val_loss: 0.5665 - val_accuracy: 0.7752\n",
      "Epoch 304/1000\n",
      "7/7 [==============================] - 2s 234ms/step - loss: 0.5763 - accuracy: 0.7717 - val_loss: 0.5663 - val_accuracy: 0.7754\n",
      "Epoch 305/1000\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.5757 - accuracy: 0.7718 - val_loss: 0.5664 - val_accuracy: 0.7754\n",
      "Epoch 306/1000\n",
      "7/7 [==============================] - 1s 215ms/step - loss: 0.5757 - accuracy: 0.7720 - val_loss: 0.5665 - val_accuracy: 0.7753\n",
      "Epoch 307/1000\n",
      "7/7 [==============================] - 2s 258ms/step - loss: 0.5756 - accuracy: 0.7721 - val_loss: 0.5664 - val_accuracy: 0.7752\n",
      "Epoch 308/1000\n",
      "7/7 [==============================] - 1s 205ms/step - loss: 0.5759 - accuracy: 0.7718 - val_loss: 0.5665 - val_accuracy: 0.7750\n",
      "Epoch 309/1000\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.5758 - accuracy: 0.7719 - val_loss: 0.5665 - val_accuracy: 0.7750\n",
      "Epoch 310/1000\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5758 - accuracy: 0.7717 - val_loss: 0.5664 - val_accuracy: 0.7752\n",
      "Epoch 311/1000\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.5762 - accuracy: 0.7720 - val_loss: 0.5664 - val_accuracy: 0.7750\n",
      "Epoch 312/1000\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.5757 - accuracy: 0.7721 - val_loss: 0.5665 - val_accuracy: 0.7751\n",
      "Epoch 313/1000\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5759 - accuracy: 0.7719 - val_loss: 0.5669 - val_accuracy: 0.7747\n",
      "Epoch 314/1000\n",
      "7/7 [==============================] - 1s 155ms/step - loss: 0.5759 - accuracy: 0.7715 - val_loss: 0.5666 - val_accuracy: 0.7750\n",
      "Epoch 315/1000\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.5757 - accuracy: 0.7719 - val_loss: 0.5663 - val_accuracy: 0.7753\n",
      "Epoch 316/1000\n",
      "7/7 [==============================] - 1s 154ms/step - loss: 0.5760 - accuracy: 0.7720 - val_loss: 0.5663 - val_accuracy: 0.7752\n",
      "Epoch 317/1000\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5756 - accuracy: 0.7718 - val_loss: 0.5662 - val_accuracy: 0.7754\n",
      "Epoch 318/1000\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5757 - accuracy: 0.7720 - val_loss: 0.5663 - val_accuracy: 0.7754\n",
      "Epoch 319/1000\n",
      "7/7 [==============================] - 1s 162ms/step - loss: 0.5753 - accuracy: 0.7723 - val_loss: 0.5663 - val_accuracy: 0.7751\n",
      "Epoch 320/1000\n",
      "7/7 [==============================] - 1s 147ms/step - loss: 0.5753 - accuracy: 0.7721 - val_loss: 0.5663 - val_accuracy: 0.7753\n",
      "Epoch 321/1000\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.5756 - accuracy: 0.7717 - val_loss: 0.5665 - val_accuracy: 0.7749\n",
      "Epoch 322/1000\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5758 - accuracy: 0.7720 - val_loss: 0.5665 - val_accuracy: 0.7749\n",
      "Epoch 323/1000\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.5757 - accuracy: 0.7723 - val_loss: 0.5665 - val_accuracy: 0.7750\n",
      "Epoch 324/1000\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.5757 - accuracy: 0.7723 - val_loss: 0.5664 - val_accuracy: 0.7750\n",
      "Epoch 325/1000\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.5755 - accuracy: 0.7721 - val_loss: 0.5662 - val_accuracy: 0.7754\n",
      "Epoch 326/1000\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5754 - accuracy: 0.7722 - val_loss: 0.5663 - val_accuracy: 0.7753\n",
      "Epoch 327/1000\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.5755 - accuracy: 0.7723 - val_loss: 0.5662 - val_accuracy: 0.7753\n",
      "Epoch 328/1000\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.5752 - accuracy: 0.7720 - val_loss: 0.5664 - val_accuracy: 0.7750\n",
      "Epoch 329/1000\n",
      "7/7 [==============================] - 1s 148ms/step - loss: 0.5753 - accuracy: 0.7718 - val_loss: 0.5664 - val_accuracy: 0.7752\n",
      "Epoch 330/1000\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.5754 - accuracy: 0.7721 - val_loss: 0.5664 - val_accuracy: 0.7750\n",
      "Epoch 331/1000\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 0.5755 - accuracy: 0.7725 - val_loss: 0.5664 - val_accuracy: 0.7751\n",
      "Epoch 332/1000\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 0.5752 - accuracy: 0.7720 - val_loss: 0.5662 - val_accuracy: 0.7750\n",
      "6250/6250 [==============================] - 16s 2ms/step - loss: 0.5677 - accuracy: 0.7743\n",
      "test_loss:  0.5676530599594116\n",
      "test_acc:  0.7743300199508667\n"
     ]
    }
   ],
   "source": [
    "my_model = MLP(X_train, Y_train, X_test, Y_test, 32, 32)\n",
    "my_model.generate_model()\n",
    "my_model.train_model()\n",
    "score = my_model.evaluate_model()\n",
    "print('test_loss: ', score[0])\n",
    "print('test_acc: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb6cdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                224       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,412\n",
      "Trainable params: 1,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "my_model.show_model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58d76347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model.show_train_val_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3009e02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "은닉층 활성함수 :  relu\n",
      "출력층 활성함수:  softmax\n",
      "손실함수 :  categorical_crossentropy\n",
      "최적화 기법 :  adam\n"
     ]
    }
   ],
   "source": [
    "my_model.get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad8320af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "my_model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "969e510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,412\n",
      "Trainable params: 1,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델 loading\n",
    "loaded_model = load_model(\"dnn_term_project.h5\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d7762c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 160, 105, 98, 25, 40]\n",
      "[2, 0.8421052631578947, 0.875, 0.4134078212290503, 0.620347394540943, 0.5714285714285714]\n",
      "[[0.33020613 0.22143085 0.19667351 0.25168955]]\n",
      "1\n",
      "고혈압/당뇨병 진료내역 있음\n"
     ]
    }
   ],
   "source": [
    "# 새로운 샘플의 클래스 예측하기\n",
    "X_new = [2, 160, 105, 98, 25, 40]\n",
    "X_new_scaled = [2, 160/190, 105/120, 148/358, 25/40.3, 40/70]\n",
    "print(X_new)\n",
    "print(X_new_scaled)\n",
    "Y_prob = loaded_model.predict([X_new_scaled])\n",
    "print(Y_prob)\n",
    "Y_pred = Y_prob.argmax()\n",
    "print(Y_pred + 1)\n",
    "\n",
    "# 1 : 고혈압/당뇨병 진료내역 있음, 2 : 고혈압 진료내역 있음, 3 : 당뇨 진료내역 있음, 4 : 진료내역 없음\n",
    "if(Y_pred + 1 == 1) :\n",
    "    print(\"고혈압/당뇨병 진료내역 있음\")\n",
    "elif(Y_pred + 1 == 2) :\n",
    "    print(\"고혈압 진료내역 있음\")\n",
    "elif(Y_pred + 1 == 3) :\n",
    "    print(\"당뇨 진료내역 있음\")\n",
    "else :\n",
    "    print(\"진료내역 없음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b79f1",
   "metadata": {},
   "source": [
    "#### 결론\n",
    " 학습된 모델의 정확도는 약 77.5%로 예상보다 다소 낮았다. 그 이유는 현재 가설은 성별, 연령대, 수축기혈압, 이완기혈압, 공복기혈당, 체질량지수만을 활용해 고혈압과 당뇨병의 진료여부를 예측하는 것인데, 실제로는 더 많은 요인이 고혈압과 당뇨병의 원인으로 작용하기 때문이다. 하지만, 위의 예측과 같이 혈압이 160/105, 공복기혈당이 148로 상당히 높은 경우에 대해서는 고혈압 및 당뇨병의 진료 내역이 있을 것이라는 유의미한 결과를 도출한다. 또한, 현재 가진 데이터 중에서 진료내역이 없는 환자가 전체 데이터 중에서 약 74% 이상을 차지하는 것을 볼 수 있는데, 고혈압 및 당뇨병 진료를 받은 환자들의 데이터에 비해 월등히 많은 것으로 판단된다. 이런 데이터의 불균형이 생기기 때문에 학습이 생각보다 잘 진행되지 않는 어려움은 있었으나, 모든 데이터에 대해 진료 내역이 없다고 판단하는 모델의 경우에 74% 정도의 정확도가 측정이 되지만, 현재 정확도는 약 77.5%이므로 모델 성능이 비교적 높다고 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2689f",
   "metadata": {},
   "source": [
    "#### 참고문헌\n",
    "기계학습 by 오일석"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
